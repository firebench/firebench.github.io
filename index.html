<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="FIRE-Bench evaluates AI research agents on their ability to autonomously rediscover established scientific findings from recent ML research.">
  <meta name="keywords" content="FIRE-Bench, AI Research Agents, Scientific Discovery, LLM Evaluation, Benchmark">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>FIRE-Bench: Evaluating Research Agents on the Rediscovery of Scientific Insights</title>

  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css?v=6">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <!-- Research Tree Visualization Styles -->
  <style>
    .research-tree-section {
      background: #FFFFFF;
      padding: 4rem 1.5rem;
    }

    .research-tree-section .section-title,
    .research-tree-section .section-subtitle {
      color: #1a1a1a;
    }

    .research-tree-section .section-subtitle {
      color: #666666;
      margin-bottom: 2rem;
    }

    .tree-paper-selector {
      display: flex;
      justify-content: center;
      gap: 10px;
      flex-wrap: wrap;
      margin-bottom: 20px;
    }

    .tree-paper-tab {
      padding: 12px 20px;
      background: #f5f5f5;
      border: 2px solid #e0e0e0;
      border-radius: 10px;
      cursor: pointer;
      transition: all 0.3s ease;
      text-align: center;
      max-width: 350px;
    }

    .tree-paper-tab:hover {
      background: #eeeeee;
      border-color: #bdbdbd;
    }

    .tree-paper-tab.active {
      background: rgba(100, 181, 246, 0.15);
      border-color: #2196f3;
    }

    .tree-tab-title {
      font-size: 0.85em;
      font-weight: 600;
      color: #1a1a1a;
      margin-bottom: 4px;
    }

    .tree-tab-venue {
      font-size: 0.75em;
      color: #666666;
    }

    /* Main Layout with Sidebar */
    .tree-main-layout {
      display: flex;
      gap: 20px;
      align-items: flex-start;
    }

    .tree-sidebar {
      flex-shrink: 0;
      width: 160px;
      position: sticky;
      top: 100px;
    }

    .tree-content-area {
      flex: 1;
      min-width: 0;
    }

    .tree-controls-vertical {
      display: flex;
      flex-direction: column;
      gap: 8px;
      margin-bottom: 20px;
    }

    .tree-controls-vertical button {
      background: #f5f5f5;
      border: 1px solid #e0e0e0;
      color: #1a1a1a;
      padding: 10px 14px;
      border-radius: 8px;
      cursor: pointer;
      transition: all 0.3s ease;
      font-family: inherit;
      font-size: 0.85em;
      text-align: left;
    }

    .tree-controls-vertical button:hover {
      background: #eeeeee;
      border-color: #bdbdbd;
    }

    .tree-legend-vertical {
      display: flex;
      flex-direction: column;
      gap: 10px;
      padding: 15px;
      background: #f9f9f9;
      border: 1px solid #e0e0e0;
      border-radius: 10px;
    }

    .tree-legend-item {
      display: flex;
      align-items: center;
      gap: 10px;
      font-size: 0.85em;
      color: #333333;
    }

    .tree-legend-color {
      width: 20px;
      height: 20px;
      border-radius: 4px;
      flex-shrink: 0;
    }

    .tree-legend-root { background: linear-gradient(135deg, #6a1b9a 0%, #8e24aa 100%); }
    .tree-legend-d1 { background: linear-gradient(135deg, #1565c0 0%, #1976d2 100%); }
    .tree-legend-d2 { background: linear-gradient(135deg, #00695c 0%, #00897b 100%); }
    .tree-legend-d3 { background: linear-gradient(135deg, #bf360c 0%, #e64a19 100%); }
    .tree-legend-leaf { background: linear-gradient(135deg, #37474f 0%, #455a64 100%); }

    .tree-paper-content {
      display: none;
    }

    .tree-paper-content.active {
      display: block;
    }

    .tree-header {
      text-align: center;
      margin-bottom: 30px;
      padding: 20px;
      background: #f9f9f9;
      border: 1px solid #e0e0e0;
      border-radius: 15px;
    }

    .tree-header h3 {
      font-size: 1.4em;
      color: #1976d2;
      margin-bottom: 10px;
      line-height: 1.3;
    }

    .tree-header .tree-authors {
      font-size: 0.9em;
      color: #666666;
      margin-bottom: 5px;
    }

    .tree-header .tree-venue {
      font-size: 0.85em;
      color: #888888;
    }

    .tree-stats-bar {
      display: flex;
      justify-content: center;
      gap: 30px;
      margin-bottom: 20px;
      padding: 10px;
      background: #fafafa;
      border-radius: 8px;
    }

    .tree-stat-item {
      text-align: center;
    }

    .tree-stat-value {
      font-size: 1.5em;
      font-weight: 700;
      color: #1976d2;
    }

    .tree-stat-label {
      font-size: 0.75em;
      color: #888888;
      text-transform: uppercase;
    }

    .tree-container {
      max-width: 1200px;
      margin: 0 auto;
    }

    .tree-node {
      margin: 10px 0;
      border-radius: 12px;
      overflow: hidden;
      transition: all 0.3s ease;
    }

    .tree-node-header {
      padding: 15px 20px;
      cursor: pointer;
      display: flex;
      align-items: flex-start;
      gap: 12px;
      transition: background 0.3s ease;
    }

    .tree-node-header:hover {
      filter: brightness(0.95);
    }

    .tree-toggle-icon {
      font-size: 1.2em;
      min-width: 20px;
      transition: transform 0.3s ease;
      color: #fff;
    }

    .tree-node.collapsed .tree-toggle-icon {
      transform: rotate(-90deg);
    }

    .tree-node-type {
      font-size: 0.7em;
      padding: 3px 8px;
      border-radius: 4px;
      text-transform: uppercase;
      font-weight: 600;
      white-space: nowrap;
    }

    .tree-node-title {
      flex: 1;
      font-weight: 500;
      line-height: 1.4;
      color: #fff;
    }

    .tree-node-content {
      padding: 0 20px 15px 52px;
      display: none;
    }

    .tree-node:not(.collapsed) > .tree-node-content {
      display: block;
    }

    .tree-node-description {
      font-size: 0.9em;
      color: #555555;
      margin-bottom: 10px;
      line-height: 1.5;
    }

    .tree-node-evidence {
      font-size: 0.8em;
      color: #2e7d32;
      background: rgba(46, 125, 50, 0.1);
      padding: 8px 12px;
      border-radius: 6px;
      margin-bottom: 10px;
    }

    .tree-children {
      margin-left: 25px;
      border-left: 2px solid #e0e0e0;
      padding-left: 15px;
    }

    /* Root Node */
    .tree-root-node > .tree-node-header {
      background: linear-gradient(135deg, #6a1b9a 0%, #8e24aa 100%);
    }
    .tree-root-node .tree-node-type {
      background: rgba(255, 255, 255, 0.2);
      color: #fff;
    }

    /* Depth-1 Nodes */
    .tree-depth-1-node > .tree-node-header {
      background: linear-gradient(135deg, #1565c0 0%, #1976d2 100%);
    }
    .tree-depth-1-node .tree-node-type {
      background: rgba(255, 255, 255, 0.2);
      color: #fff;
    }

    /* Depth-2 Nodes */
    .tree-depth-2-node > .tree-node-header {
      background: linear-gradient(135deg, #00695c 0%, #00897b 100%);
    }
    .tree-depth-2-node .tree-node-type {
      background: rgba(255, 255, 255, 0.2);
      color: #fff;
    }

    /* Depth-3 Nodes */
    .tree-depth-3-node > .tree-node-header {
      background: linear-gradient(135deg, #bf360c 0%, #e64a19 100%);
    }
    .tree-depth-3-node .tree-node-type {
      background: rgba(255, 255, 255, 0.2);
      color: #fff;
    }

    /* Leaf Nodes */
    .tree-leaf-node > .tree-node-header {
      background: linear-gradient(135deg, #37474f 0%, #455a64 100%);
    }
    .tree-leaf-node .tree-node-type {
      background: #ffc107;
      color: #212121;
    }

    .tree-leaf-details {
      display: grid;
      gap: 10px;
      margin-top: 10px;
    }

    .tree-detail-row {
      display: grid;
      grid-template-columns: 120px 1fr;
      gap: 10px;
      font-size: 0.85em;
    }

    .tree-detail-label {
      color: #90a4ae;
      font-weight: 600;
    }

    .tree-detail-value {
      color: #cfd8dc;
    }

    .tree-tag {
      display: inline-block;
      background: rgba(100, 181, 246, 0.2);
      color: #64b5f6;
      padding: 2px 8px;
      border-radius: 4px;
      font-size: 0.85em;
      margin: 2px;
    }

    .tree-conclusion-box {
      background: rgba(129, 199, 132, 0.15);
      border-left: 3px solid #81c784;
      padding: 12px;
      border-radius: 0 8px 8px 0;
      margin-top: 10px;
    }

    .tree-conclusion-box .tree-label {
      color: #81c784;
      font-weight: 600;
      margin-bottom: 5px;
      font-size: 0.8em;
      text-transform: uppercase;
    }

    .tree-conclusion-box .tree-text {
      color: #c8e6c9;
      font-size: 0.9em;
      line-height: 1.5;
    }

    .tree-evidence-refs {
      display: flex;
      gap: 10px;
      flex-wrap: wrap;
      margin-top: 8px;
    }

    .tree-evidence-ref {
      background: rgba(255, 255, 255, 0.1);
      padding: 4px 10px;
      border-radius: 4px;
      font-size: 0.8em;
      color: #b0bec5;
    }

    /* View Toggle Styles */
    .tree-view-toggle {
      display: flex;
      justify-content: center;
      gap: 10px;
      margin-bottom: 20px;
    }

    .tree-view-btn {
      display: flex;
      align-items: center;
      gap: 8px;
      padding: 12px 24px;
      background: #f5f5f5;
      border: 2px solid #e0e0e0;
      border-radius: 10px;
      color: #1a1a1a;
      cursor: pointer;
      transition: all 0.3s ease;
      font-family: inherit;
      font-size: 0.95em;
      font-weight: 500;
    }

    .tree-view-btn:hover {
      background: #eeeeee;
      border-color: #bdbdbd;
    }

    .tree-view-btn.active {
      background: rgba(33, 150, 243, 0.15);
      border-color: #2196f3;
      color: #1976d2;
    }

    .view-icon {
      font-size: 1.1em;
    }

    .tree-view-container {
      display: none;
    }

    .tree-view-container.active {
      display: block;
    }

    /* Visual Diagram Styles */
    .tree-diagram-content {
      display: none;
    }

    .tree-diagram-content.active {
      display: block;
    }

    .tree-diagram-wrapper {
      background: linear-gradient(180deg, #f8fafc 0%, #e2e8f0 100%);
      border-radius: 16px;
      padding: 30px 20px;
      max-width: 1150px;
      margin: 0 auto;
      overflow-x: auto;
    }

    .tree-svg-diagram {
      width: 100%;
      min-width: 900px;
      height: auto;
      display: block;
    }

    .tree-diagram-placeholder {
      background: #f9f9f9;
      border: 2px dashed #e0e0e0;
      border-radius: 16px;
      padding: 60px 40px;
      text-align: center;
      max-width: 600px;
      margin: 0 auto;
    }

    .tree-diagram-placeholder .placeholder-icon {
      font-size: 4em;
      margin-bottom: 20px;
      opacity: 0.7;
    }

    .tree-diagram-placeholder h4 {
      color: #1a1a1a;
      font-size: 1.4em;
      margin-bottom: 15px;
    }

    .tree-diagram-placeholder p {
      color: #666666;
      font-size: 1em;
      line-height: 1.6;
      margin-bottom: 8px;
    }

    @media (max-width: 900px) {
      .tree-main-layout {
        flex-direction: column;
      }

      .tree-sidebar {
        width: 100%;
        position: static;
        flex-direction: row;
        gap: 15px;
        flex-wrap: wrap;
        justify-content: center;
      }

      .tree-sidebar[style*="display: block"] {
        display: flex !important;
      }

      .tree-controls-vertical {
        flex-direction: row;
        flex-wrap: wrap;
        justify-content: center;
        margin-bottom: 0;
      }

      .tree-controls-vertical button {
        text-align: center;
      }

      .tree-legend-vertical {
        flex-direction: row;
        flex-wrap: wrap;
        justify-content: center;
        gap: 15px;
      }
    }

    @media (max-width: 768px) {
      .tree-paper-selector {
        flex-direction: column;
        align-items: center;
      }
      
      .tree-paper-tab {
        width: 100%;
        max-width: 100%;
      }
      
      .tree-controls-vertical button {
        padding: 8px 12px;
        font-size: 0.8em;
      }
      
      .tree-detail-row {
        grid-template-columns: 1fr;
      }
      
      .tree-stats-bar {
        gap: 15px;
      }

      .tree-view-toggle {
        flex-direction: column;
        align-items: center;
      }

      .tree-view-btn {
        width: 100%;
        max-width: 300px;
        justify-content: center;
      }

      .tree-diagram-wrapper {
        padding: 15px 10px;
      }

      .tree-diagram-placeholder {
        padding: 40px 20px;
      }
    }
  </style>
</head>
<body>

<!-- Sticky Navigation -->
<nav class="navbar is-fixed-top main-nav" role="navigation" aria-label="main navigation">
  <div class="container">
    <div class="navbar-brand">
      <a class="navbar-item nav-logo" href="#">
        <span class="fire-logo">üî•</span> FIRE-Bench
      </a>
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false" data-target="mainNavbar">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div id="mainNavbar" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="#framework">Framework</a>
        <a class="navbar-item" href="#method">Method</a>
        <a class="navbar-item" href="#leaderboard">Leaderboard</a>
        <a class="navbar-item" href="#tasks">Tasks</a>
        <a class="navbar-item" href="#research-tree">Research Tree</a>
        <a class="navbar-item" href="#analysis">Analysis</a>
        <a class="navbar-item" href="#BibTeX">Cite</a>
      </div>
    </div>
  </div>
</nav>

<!-- 1. HERO SECTION -->
<section class="hero hero-header" id="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            <span class="fire-logo">üî•</span> FIRE-Bench
          </h1>
          <p class="hero-tagline">
            Can AI agents rediscover scientific insights? We benchmark full-cycle research automation with verifiable evaluation.
          </p>
          <div class="is-size-6 publication-authors">
            <span class="author-block">
              <a href="https://zhenwang9102.github.io/" target="_blank">Zhen Wang</a>*<sup>1</sup>, <a href="https://bflashcp3f.github.io/" target="_blank">Fan Bai</a>*<sup>2</sup>, Zhongyan Luo*<sup>1</sup>, <a href="https://jinyansu1.github.io/" target="_blank">Jinyan Su</a><sup>3</sup>, <a href="https://kaiserwholearns.github.io/" target="_blank">Kaiser Sun</a><sup>2</sup>, Xinle Yu<sup>1</sup>, Jieyuan Liu<sup>1</sup>, <a href="https://lancelot39.github.io/" target="_blank">Kun Zhou</a><sup>1</sup>, <a href="https://www.cs.cornell.edu/home/cardie/" target="_blank">Claire Cardie</a><sup>3</sup>, <a href="https://www.cs.jhu.edu/~mdredze/" target="_blank">Mark Dredze</a><sup>2</sup>, <a href="http://www.cs.cmu.edu/~epxing/" target="_blank">Eric P. Xing</a><sup>4,5</sup>, <a href="https://zhiting.ucsd.edu/" target="_blank">Zhiting Hu</a><sup>1</sup>
            </span>
          </div>
          <div class="is-size-7 publication-affiliations">
            <span class="affiliation-block"><sup>1</sup>UC San Diego, <sup>2</sup>Johns Hopkins University, <sup>3</sup>Cornell University, <sup>4</sup>MBZUAI, <sup>5</sup>CMU</span>
            <br>
            <span class="affiliation-note">* Equal Contribution</span>
          </div>

          <div class="publication-links">
            <span class="link-block">
              <a href="./static/FIRE_Bench.pdf" class="external-link button is-normal is-rounded is-dark" target="_blank">
                <span class="icon"><i class="fas fa-file-pdf"></i></span>
                <span>Paper</span>
              </a>
            </span>
            <span class="link-block">
              <a href="#" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="ai ai-arxiv"></i></span>
                <span>arXiv</span>
              </a>
            </span>
            <span class="link-block">
              <a href="#" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fab fa-github"></i></span>
                <span>Code</span>
              </a>
            </span>
            <span class="link-block">
              <a href="#" class="external-link button is-normal is-rounded is-dark">
                <span class="icon"><i class="fas fa-database"></i></span>
                <span>Benchmark</span>
              </a>
            </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- ANNOUNCEMENT BANNER -->
<section class="announcement-banner">
  <div class="container">
    <div class="announcement-content">
      <span class="announcement-badge">Coming Soon</span>
      <p class="announcement-text">
        <strong>Live FIRE-Bench</strong> ‚Äî Upload your own research paper and see how AI agents perform on your tasks!
      </p>
    </div>
  </div>
</section>


<!-- 2. FRAMEWORK ANIMATION VIDEO -->
<section class="section video-section" id="framework">
  <div class="container is-max-widescreen">
    <div class="video-container">
      <h3 class="video-title has-text-centered">Framework Animation</h3>
      <p class="video-description has-text-centered">Papers are parsed into tree-structured tasks, where each node represents an executable, verifiable research step.</p>
      <video class="framework-video" controls muted loop playsinline>
        <source src="./static/videos/fire-bench-framework.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
    </div>
  </div>
</section>


<!-- 3. METHOD SECTION -->
<section class="section method-section" id="method">
  <div class="container is-max-desktop">
    <h2 class="title is-3 section-title has-text-centered">Methodology</h2>
    <p class="section-subtitle has-text-centered">
      From Papers to Verifiable Discovery Tasks
    </p>

    <div class="method-content">
      <p>
        FIRE-Bench is constructed through <strong>research-problem decomposition</strong>, a process that transforms high-quality 
        empirical analysis papers into verifiable benchmark tasks. This approach balances exploratory freedom (avoiding tasks that 
        are too broad to benchmark) with empirical verifiability (avoiding tasks that are too narrow to allow genuine exploration).
      </p>
      <p>
        We formalize each paper \(\mathcal{P}\) as a hierarchical research-problem tree \(\mathcal{T}(\mathcal{P})\) 
        that encodes the authors' reasoning trajectory, from broad research questions (e.g., "Do LLMs contain biases?") to specific 
        experimental tasks. The tree is extracted via an automated parser: \(E_\phi: \Sigma^* \rightarrow \mathcal{T},\; \mathcal{T}(\mathcal{P}) = E_\phi(\mathcal{P})\). 
        It consists of three node types: Root node \(r\) captures the overarching 
        research problem from the paper's title or abstract; Intermediate nodes \(v_i \in \mathcal{V}\) represent narrower 
        subproblems that decompose the main question (e.g., "Do LLMs exhibit racial bias in medical report generation?"); Leaf nodes 
        \(l_j \in \mathcal{L}\) specify fully executable experiments with datasets \(\mathcal{D}_j\), 
        methods \(\mathcal{M}_j\), and evaluation metrics \(\mathcal{C}_j\), each mapping directly to 
        figures or tables in the original paper.
      </p>
      <p>
        From each tree, we create a <strong>"constrained rediscovery" problem</strong> by first identifying a target leaf node 
        \(l^* \in \mathcal{L}\) corresponding to a central finding, then selecting an intermediate node 
        \(v^* \in \mathcal{V}\) that balances openness with verifiability. The agent receives only the research question 
        from \(v^*\), while the methodology and conclusion from \(l^*\) are withheld. 
        The paper's published findings serve as ground truth for evaluation.
      </p>
      <p>
        We evaluate agent performance through claim-level analysis: both agent conclusions \(C_{\text{agent}}\) 
        and ground truth \(C_{\text{gt}}\) are decomposed into atomic, verifiable claims. We then compute 
        \(\text{Precision}\), \(\text{Recall}\), and \(F_1\) as the overall performance metric.
      </p>
    </div>
  </div>
</section>


<!-- 4. HIGHLIGHTS SECTION -->
<section class="section highlights-section">
  <div class="container is-max-desktop">
    <div class="highlights-grid">
      <div class="highlight-card">
        <div class="highlight-stat">30</div>
        <div class="highlight-title">Research Tasks</div>
        <div class="highlight-desc">Derived from ICLR, ICML, and NeurIPS papers (2024-2025)</div>
      </div>
      <div class="highlight-card">
        <div class="highlight-stat">‚úì</div>
        <div class="highlight-title">Verifiable Evaluation</div>
        <div class="highlight-desc">Ground truth from published papers enables objective scoring</div>
      </div>
      <div class="highlight-card">
        <div class="highlight-stat">4</div>
        <div class="highlight-title">Research Stages</div>
        <div class="highlight-desc">Plan ‚Üí Implement ‚Üí Execute ‚Üí Analyze the full research cycle</div>
      </div>
      <div class="highlight-card">
        <div class="highlight-stat">14</div>
        <div class="highlight-title">Error Categories</div>
        <div class="highlight-desc">Fine-grained taxonomy reveals where agents fail</div>
      </div>
    </div>
  </div>
</section>





<!-- 4. LEADERBOARD SECTION -->
<section class="section leaderboard-section" id="leaderboard">
  <div class="container is-max-desktop">
    <h2 class="title is-3 section-title has-text-centered">Leaderboard</h2>
    <p class="section-subtitle has-text-centered">
      Mean scores with standard deviation across three independent trials on all 30 tasks
    </p>

    <table class="performance-table">
      <thead>
        <tr>
          <th class="col-rank">#</th>
          <th class="col-agent">Agent</th>
          <th class="col-metric">Precision</th>
          <th class="col-metric">Recall</th>
          <th class="col-metric">F‚ÇÅ Score</th>
        </tr>
      </thead>
      <tbody>
        <tr class="best-row">
          <td class="rank-cell">1</td>
          <td class="agent-cell">
            <span class="agent-name">Claude Code</span>
            <span class="agent-model">Sonnet-4</span>
          </td>
          <td>52.1</td>
          <td>48.3</td>
          <td class="f1-cell"><strong>46.7</strong></td>
        </tr>
        <tr>
          <td class="rank-cell">2</td>
          <td class="agent-cell">
            <span class="agent-name">Codex CLI</span>
            <span class="agent-model">gpt-5-medium</span>
          </td>
          <td>44.83</td>
          <td>48.96</td>
          <td class="f1-cell">41.93</td>
        </tr>
        <tr>
          <td class="rank-cell">3</td>
          <td class="agent-cell">
            <span class="agent-name">OpenHands</span>
            <span class="agent-model">gpt-5</span>
          </td>
          <td>41.67</td>
          <td>41.42</td>
          <td class="f1-cell">37.87</td>
        </tr>
        <tr>
          <td class="rank-cell">4</td>
          <td class="agent-cell">
            <span class="agent-name">OpenHands</span>
            <span class="agent-model">o4-mini</span>
          </td>
          <td>36.81</td>
          <td>36.63</td>
          <td class="f1-cell">31.85</td>
        </tr>
      </tbody>
    </table>

    <div class="key-findings">
      <div class="finding-card">
        <div class="finding-icon">üìâ</div>
        <div class="finding-content">
          <strong>Low Performance</strong>
          <p>Best agent achieves only 46.7 F‚ÇÅ</p>
        </div>
      </div>
      <div class="finding-card">
        <div class="finding-icon">üìà</div>
        <div class="finding-content">
          <strong>High Variance</strong>
          <p>Success often appears to be a "lottery"</p>
        </div>
      </div>
      <div class="finding-card">
        <div class="finding-icon">üß†</div>
        <div class="finding-content">
          <strong>Planning Bottleneck</strong>
          <p>73.6% of errors from flawed planning</p>
        </div>
      </div>
    </div>

    <p class="leaderboard-note has-text-centered">More agents are being added...</p>
  </div>
</section>


<!-- 5. TASK EXAMPLES SECTION -->
<section class="section tasks-section" id="tasks">
  <div class="container is-max-desktop">
    <h2 class="title is-3 section-title has-text-centered">Benchmark Tasks</h2>
    <p class="section-subtitle has-text-centered">
      30 research tasks from high-impact ML papers. Click to see details.
    </p>

    <div class="task-filters">
      <button class="task-filter active" data-filter="all">All</button>
      <button class="task-filter" data-filter="iclr">ICLR</button>
      <button class="task-filter" data-filter="icml">ICML</button>
      <button class="task-filter" data-filter="neurips">NeurIPS</button>
    </div>

    <div class="tasks-grid-interactive">
      <!-- Original 9 papers for "All" tab -->
      <div class="task-card-expandable" data-venue="featured" data-featured="true">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">TACL 2024</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">Lost in the Middle</h4>
          <p class="task-description">Do language models use information equally regardless of its position in context?</p>
          <div class="task-meta">
            <span class="task-topic-tag">Context Position Effects</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>How does the position of relevant information within long contexts affect language model performance on retrieval tasks?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>Multi-document QA with multiple documents, varying the position of the gold document.</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>Performance follows a U-shaped curve: models perform best when relevant information is at the beginning or end, with significant degradation for middle positions.</p>
          </div>
        </div>
      </div>

      <div class="task-card-expandable" data-venue="featured" data-featured="true">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">Nature 2024</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">LLM Racial Bias in Medicine</h4>
          <p class="task-description">Do clinical LLMs propagate race-based medical misconceptions?</p>
          <div class="task-meta">
            <span class="task-topic-tag">Healthcare Bias</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>Do LLMs exhibit racial bias when generating medical reports and predictions for different demographic groups?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>Generate medical predictions (hospitalization, costs, mortality) for patient cases while systematically varying racial/ethnic information.</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>Models show significant racial biases: higher costs projected for White populations, optimistic survival predictions, and disease-race associations mirroring real-world disparities.</p>
          </div>
        </div>
      </div>

      <div class="task-card-expandable" data-venue="featured" data-featured="true">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">ICLR 2024</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">LLMs Lack Self-Correction</h4>
          <p class="task-description">Can LLMs improve reasoning by self-correction without external feedback?</p>
          <div class="task-meta">
            <span class="task-topic-tag">Reasoning Behavior</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>Can large language models improve their reasoning performance through intrinsic self-correction without any external feedback?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>Test self-correction on GSM8K, CommonSenseQA, and HotpotQA using prompts that ask models to review and revise their answers.</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>LLMs cannot reliably self-correct reasoning without external feedback. Performance often degrades as models change correct answers to incorrect ones.</p>
          </div>
        </div>
      </div>

      <div class="task-card-expandable" data-venue="featured" data-featured="true">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">arXiv 2025</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">Awareness Detection</h4>
          <p class="task-description">Can models detect whether an interaction comes from evaluation or deployment?</p>
          <div class="task-meta">
            <span class="task-topic-tag">Evaluation Awareness</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>Can frontier LLMs distinguish between evaluation/benchmark prompts and real-world deployment interactions?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>Binary classification task on diverse prompts from multiple datasets including MMLU, SWEBench, and real-world interactions.</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>Gemini-2.5-Pro achieves AUC of 0.83 in identifying evaluations, demonstrating significant evaluation awareness capability.</p>
          </div>
        </div>
      </div>

      <div class="task-card-expandable" data-venue="featured" data-featured="true">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">arXiv 2025</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">CoT Faithfulness Gaps</h4>
          <p class="task-description">Do chain-of-thought explanations faithfully reflect model reasoning?</p>
          <div class="task-meta">
            <span class="task-topic-tag">Reasoning Faithfulness</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>When reasoning models use hints to solve problems, do they faithfully acknowledge these hints in their chain-of-thought?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>Insert various hints into prompts and measure how often models mention using the hints in their reasoning traces.</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>Models use hints but rarely mention them in their reasoning. Reveal rates are consistently low across different model families.</p>
          </div>
        </div>
      </div>

      <div class="task-card-expandable" data-venue="featured" data-featured="true">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">NeurIPS 2024</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">CoT Without Prompting</h4>
          <p class="task-description">Can altered decoding reveal latent reasoning paths in LLMs?</p>
          <div class="task-meta">
            <span class="task-topic-tag">Decoding Strategies</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>Can chain-of-thought reasoning paths be extracted from LLMs by modifying the decoding process rather than prompting?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>Compare greedy decoding vs. top-k alternative token exploration on GSM8K and other reasoning benchmarks.</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>CoT reasoning paths are inherent in alternative decoding sequences. CoT-decoding substantially outperforms standard greedy decoding.</p>
          </div>
        </div>
      </div>

      <div class="task-card-expandable" data-venue="featured" data-featured="true">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">ICML 2024</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">Hallucination Snowballing</h4>
          <p class="task-description">Do LLM hallucinations compound when models build on prior errors?</p>
          <div class="task-meta">
            <span class="task-topic-tag">Error Propagation</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>Do language models generate hallucinations that they could recognize as incorrect if presented in isolation?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>QA datasets on primality testing, senator searches, and flight connectivity. Test if models can identify their own false claims separately.</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>Models over-commit to early mistakes. They can identify most of their own incorrect claims when presented separately, yet still generate them in context.</p>
          </div>
        </div>
      </div>

      <div class="task-card-expandable" data-venue="featured" data-featured="true">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">ICML 2024</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">Counterfactual Simulatability</h4>
          <p class="task-description">Can humans predict model behavior changes from explanations?</p>
          <div class="task-meta">
            <span class="task-topic-tag">Explanation Quality</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>Do LLM explanations enable humans to accurately predict how the model would behave on variations of the input?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>Multi-hop factual reasoning and reward modeling tasks. Measure if explanations help predict model outputs on counterfactual inputs.</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>LLM explanations have low precision. Plausible-sounding explanations don't correlate with actual predictive value for model behavior.</p>
          </div>
        </div>
      </div>

      <div class="task-card-expandable" data-venue="featured" data-featured="true">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">ICML 2024</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">Premise Order Effects</h4>
          <p class="task-description">Does the order of logical premises affect LLM reasoning accuracy?</p>
          <div class="task-meta">
            <span class="task-topic-tag">Logical Reasoning</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>Are LLMs sensitive to the ordering of premises in deductive reasoning tasks, even though logical validity is order-independent?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>Deductive reasoning with permuted premise orders. R-GSM benchmark for mathematical problem-solving with reordered conditions.</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>Performance drops significantly when premises are permuted. Models perform best when premises match the proof order.</p>
          </div>
        </div>
      </div>

      <!-- ICLR Papers (for ICLR tab) -->
      <div class="task-card-expandable" data-venue="iclr">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">ICLR 2024</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">LLMs Lack Self-Correction</h4>
          <p class="task-description">Can LLMs improve reasoning by self-correction without external feedback?</p>
          <div class="task-meta">
            <span class="task-topic-tag">Reasoning Behavior</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>Can large language models improve their reasoning performance through intrinsic self-correction without any external feedback?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>Test self-correction on GSM8K, CommonSenseQA, and HotpotQA using prompts that ask models to review and revise their answers.</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>LLMs cannot reliably self-correct reasoning without external feedback. Performance often degrades as models change correct answers to incorrect ones.</p>
          </div>
        </div>
      </div>

      <div class="task-card-expandable" data-venue="iclr">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">ICLR 2024</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">Bias Runs Deep</h4>
          <p class="task-description">Do persona assignments surface implicit reasoning biases in LLMs?</p>
          <div class="task-meta">
            <span class="task-topic-tag">Persona Bias</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>Do LLMs exhibit stereotypical reasoning biases when assigned different demographic personas?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>Multiple reasoning datasets, various LLMs, and diverse personas across race, gender, religion, disability, and political affiliation.</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>Most personas showed bias across models. Some datasets had substantial performance drops with certain personas.</p>
          </div>
        </div>
      </div>

      <div class="task-card-expandable" data-venue="iclr">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">ICLR 2024</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">Not Robust MCQ Selectors</h4>
          <p class="task-description">Are LLMs robust to option position changes in multiple choice questions?</p>
          <div class="task-meta">
            <span class="task-topic-tag">Selection Bias</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>Do LLMs exhibit selection bias toward specific answer positions (A/B/C/D) regardless of content?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>MMLU and other MCQ benchmarks with permuted answer positions across multiple LLMs.</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>Moving correct answers to different positions significantly affects model accuracy, with some positions causing large performance drops and others yielding gains.</p>
          </div>
        </div>
      </div>

      <div class="task-card-expandable" data-venue="iclr">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">ICLR 2024</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">Prompt Format Sensitivity</h4>
          <p class="task-description">How sensitive are LLMs to spurious features in prompt design?</p>
          <div class="task-meta">
            <span class="task-topic-tag">Prompt Robustness</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>How much does LLM performance vary based on minor prompt formatting choices that shouldn't affect meaning?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>50+ tasks with various prompt format variations (spacing, delimiters, ordering) across multiple models.</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>Performance differences can be substantial across different prompt formats. Significant variation exists across tasks and models.</p>
          </div>
        </div>
      </div>

      <div class="task-card-expandable" data-venue="iclr">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">ICLR 2024</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">Space and Time Representations</h4>
          <p class="task-description">Do language models learn coherent representations of space and time?</p>
          <div class="task-meta">
            <span class="task-topic-tag">World Models</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>Do LLMs learn linear representations of spatial and temporal information that generalize across entity types?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>Probe LLM activations on spatial datasets (world/US/NYC places) and temporal datasets (historical figures, artworks, news).</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>LLMs learn linear space/time representations. Individual "space neurons" and "time neurons" reliably encode coordinates.</p>
          </div>
        </div>
      </div>

      <div class="task-card-expandable" data-venue="iclr">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">ICLR 2024</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">Uncertainty Expression</h4>
          <p class="task-description">Can LLMs accurately express their uncertainty about answers?</p>
          <div class="task-meta">
            <span class="task-topic-tag">Confidence Calibration</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>Can LLMs verbalize well-calibrated confidence scores that reflect their actual likelihood of being correct?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>Various prompting strategies (CoT, self-probing) across multiple LLMs on calibration and failure prediction tasks.</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>LLMs tend to be overconfident when verbalizing confidence. Calibration improves with model capability but remains far from ideal.</p>
          </div>
        </div>
      </div>

      <div class="task-card-expandable" data-venue="iclr">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">ICLR 2024</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">ICL from Repetitions</h4>
          <p class="task-description">How do surface repetitions influence in-context learning?</p>
          <div class="task-meta">
            <span class="task-topic-tag">In-Context Learning</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>Does token co-occurrence reinforcement from repeated patterns in demonstrations drive in-context learning behavior?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>Analyze ICL across OPT and LLaMA models with controlled demonstration patterns and token repetitions.</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>Surface-level repetitions significantly influence ICL. Token reinforcement can create both beneficial and spurious connections.</p>
          </div>
        </div>
      </div>

      <div class="task-card-expandable" data-venue="iclr">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">ICLR 2025</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">To CoT or Not to CoT</h4>
          <p class="task-description">When does chain-of-thought actually help LLM reasoning?</p>
          <div class="task-meta">
            <span class="task-topic-tag">CoT Analysis</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>On which task types does chain-of-thought prompting provide meaningful performance benefits?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>Meta-analysis of many papers, evaluation on diverse datasets across multiple models comparing CoT vs. direct answering.</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>CoT helps mainly on math and symbolic reasoning. On MMLU, CoT only helps when questions contain symbolic operations (equals signs).</p>
          </div>
        </div>
      </div>

      <div class="task-card-expandable" data-venue="iclr">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">ICLR 2025</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">Rationality Assumptions</h4>
          <p class="task-description">Do LLMs assume people are more rational than they really are?</p>
          <div class="task-meta">
            <span class="task-topic-tag">Human Modeling</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>Do LLMs model human decision-making as more aligned with rational choice theory than actual human behavior?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>Predict human choices between gambles using a large dataset of human risky decisions. Compare LLM predictions to actual behavior.</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>LLMs align more with expected value theory than actual human choices. They assume people are more rational than they are.</p>
          </div>
        </div>
      </div>

      <!-- ICML Papers (for ICML tab) -->
      <div class="task-card-expandable" data-venue="icml">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">ICML 2024</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">Hallucination Snowballing</h4>
          <p class="task-description">Do LLM hallucinations compound when models build on prior errors?</p>
          <div class="task-meta">
            <span class="task-topic-tag">Error Propagation</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>Do language models generate hallucinations that they could recognize as incorrect if presented in isolation?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>QA datasets on primality testing, senator searches, and flight connectivity. Test if models can identify their own false claims separately.</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>Models over-commit to early mistakes. They can identify most of their own incorrect claims when presented separately, yet still generate them in context.</p>
          </div>
        </div>
      </div>

      <div class="task-card-expandable" data-venue="icml">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">ICML 2024</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">Counterfactual Simulatability</h4>
          <p class="task-description">Can humans predict model behavior changes from explanations?</p>
          <div class="task-meta">
            <span class="task-topic-tag">Explanation Quality</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>Do LLM explanations enable humans to accurately predict how the model would behave on variations of the input?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>Multi-hop factual reasoning and reward modeling tasks. Measure if explanations help predict model outputs on counterfactual inputs.</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>LLM explanations have low precision. Plausible-sounding explanations don't correlate with actual predictive value for model behavior.</p>
          </div>
        </div>
      </div>

      <div class="task-card-expandable" data-venue="icml">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">ICML 2024</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">Premise Order Effects</h4>
          <p class="task-description">Does the order of logical premises affect LLM reasoning accuracy?</p>
          <div class="task-meta">
            <span class="task-topic-tag">Logical Reasoning</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>Are LLMs sensitive to the ordering of premises in deductive reasoning tasks, even though logical validity is order-independent?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>Deductive reasoning with permuted premise orders. R-GSM benchmark for mathematical problem-solving with reordered conditions.</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>Performance drops significantly when premises are permuted. Models perform best when premises match the proof order.</p>
          </div>
        </div>
      </div>

      <div class="task-card-expandable" data-venue="icml">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">ICML 2025</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">Fractal Complexity</h4>
          <p class="task-description">Do LLMs capture the fractal structure of natural language?</p>
          <div class="task-meta">
            <span class="task-topic-tag">Language Structure</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>Can LLMs replicate the self-similar, fractal properties and long-range dependencies found in natural language?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>Measure H√∂lder and Hurst exponents on LLM outputs vs. human text across different temperatures and prompting methods.</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>Natural language fractal parameters fall in a narrow range; LLM outputs vary widely. Larger models better capture fractal properties.</p>
          </div>
        </div>
      </div>

      <!-- NeurIPS Papers (for NeurIPS tab) -->
      <div class="task-card-expandable" data-venue="neurips">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">NeurIPS 2024</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">CoT Without Prompting</h4>
          <p class="task-description">Can altered decoding reveal latent reasoning paths in LLMs?</p>
          <div class="task-meta">
            <span class="task-topic-tag">Decoding Strategies</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>Can chain-of-thought reasoning paths be extracted from LLMs by modifying the decoding process rather than prompting?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>Compare greedy decoding vs. top-k alternative token exploration on GSM8K and other reasoning benchmarks.</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>CoT reasoning paths are inherent in alternative decoding sequences. CoT-decoding substantially outperforms standard greedy decoding.</p>
          </div>
        </div>
      </div>

      <div class="task-card-expandable" data-venue="neurips">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">NeurIPS 2024</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">Chain of Thoughtlessness</h4>
          <p class="task-description">Does CoT actually teach LLMs general algorithmic procedures?</p>
          <div class="task-meta">
            <span class="task-topic-tag">Planning Analysis</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>Does chain-of-thought prompting enable LLMs to learn generalizable algorithmic reasoning procedures?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>Blocksworld planning problems with GPT-4 and Claude-3-Opus. Test generalization beyond example complexity.</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>CoT improvements require problem-specific prompts and degrade rapidly as complexity increases beyond examples. It's pattern matching, not algorithmic learning.</p>
          </div>
        </div>
      </div>

      <div class="task-card-expandable" data-venue="neurips">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">NeurIPS 2025</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">SECA Adversarial Examples</h4>
          <p class="task-description">Can semantic-preserving prompt changes cause LLMs to hallucinate?</p>
          <div class="task-meta">
            <span class="task-topic-tag">Adversarial Robustness</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>Can realistic, meaning-preserving prompt modifications reliably trigger hallucinations in LLMs?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>Constrained optimization to find semantic-equivalent adversarial prompts that maintain coherence while eliciting hallucinations.</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>SECA achieves high attack success rates with almost no semantic or coherence errors, exposing model sensitivity to realistic variations.</p>
          </div>
        </div>
      </div>

      <div class="task-card-expandable" data-venue="neurips">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">NeurIPS 2025</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">Distributive Fairness</h4>
          <p class="task-description">How fair are LLMs in resource allocation decisions?</p>
          <div class="task-meta">
            <span class="task-topic-tag">Fairness</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>Do LLM resource allocation decisions align with human fairness principles like equitability and envy-freeness?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>Fair division tasks evaluating equitability, envy-freeness, and Rawlsian maximin principles across various allocation scenarios.</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>LLMs show stark misalignment with human distributional preferences. They cannot effectively use money to mitigate inequality.</p>
          </div>
        </div>
      </div>

      <div class="task-card-expandable" data-venue="neurips">
        <div class="task-card-interactive">
          <div class="task-card-header">
            <span class="task-venue-tag">NeurIPS 2025</span>
            <span class="expand-icon">+</span>
          </div>
          <h4 class="task-title">QuestBench</h4>
          <p class="task-description">Can LLMs ask the right questions to acquire missing information?</p>
          <div class="task-meta">
            <span class="task-topic-tag">Information Seeking</span>
          </div>
        </div>
        <div class="task-details">
          <div class="detail-section">
            <h5>Research Question</h5>
            <p>When given underspecified problems, can LLMs identify and ask the right clarifying questions?</p>
          </div>
          <div class="detail-section">
            <h5>Experiment Settings</h5>
            <p>Logic-Q, Planning-Q, GSM-Q tasks with missing variables. Models must select correct clarification questions.</p>
          </div>
          <div class="detail-section">
            <h5>Ground Truth</h5>
            <p>Models excel at math-based tasks but struggle significantly on logic and planning tasks. Solving ability doesn't transfer to asking the right questions.</p>
          </div>
        </div>
      </div>
    </div>

    <div class="tasks-more">
      <span>+ 21 more tasks in the full benchmark</span>
    </div>
  </div>
</section>


<!-- RESEARCH TREE VISUALIZATION SECTION -->
<section class="section research-tree-section" id="research-tree">
  <div class="container is-max-widescreen">
    <h2 class="title is-3 section-title has-text-centered">Research Problem Tree</h2>
    <p class="section-subtitle has-text-centered">
      Interactive visualization of paper problem trees ‚Äî click nodes to expand and explore the research structure
    </p>

    <div class="tree-paper-selector">
      <div class="tree-paper-tab active" onclick="switchTreePaper(0)">
        <div class="tree-tab-title">Lost in the Middle</div>
        <div class="tree-tab-venue">arXiv 2023</div>
      </div>
      <div class="tree-paper-tab" onclick="switchTreePaper(1)">
        <div class="tree-tab-title">LLMs Cannot Self-Correct Reasoning</div>
        <div class="tree-tab-venue">ICLR 2024</div>
      </div>
      <div class="tree-paper-tab" onclick="switchTreePaper(2)">
        <div class="tree-tab-title">Racial Bias in Medical Reports</div>
        <div class="tree-tab-venue">Comm. Medicine 2024</div>
      </div>
    </div>

    <div class="tree-view-toggle">
      <button class="tree-view-btn active" onclick="switchTreeView('interactive')">
        <span class="view-icon">üìã</span> Interactive Tree
      </button>
      <button class="tree-view-btn" onclick="switchTreeView('diagram')">
        <span class="view-icon">üå≥</span> Visual Diagram
      </button>
    </div>

    <div class="tree-main-layout">
      <!-- Left Sidebar -->
      <div class="tree-sidebar" id="tree-sidebar">
        <div class="tree-controls-vertical" id="tree-interactive-controls">
          <button onclick="expandAllTree()">Expand All</button>
          <button onclick="collapseAllTree()">Collapse All</button>
          <button onclick="expandTreeToDepth(1)">Show Depth 1</button>
          <button onclick="expandTreeToDepth(2)">Show Depth 2</button>
        </div>

        <div class="tree-legend-vertical">
          <div class="tree-legend-item"><div class="tree-legend-color tree-legend-root"></div><span>Root</span></div>
          <div class="tree-legend-item"><div class="tree-legend-color tree-legend-d1"></div><span>Depth 1</span></div>
          <div class="tree-legend-item"><div class="tree-legend-color tree-legend-d2"></div><span>Depth 2</span></div>
          <div class="tree-legend-item"><div class="tree-legend-color tree-legend-d3"></div><span>Depth 3</span></div>
          <div class="tree-legend-item"><div class="tree-legend-color tree-legend-leaf"></div><span>Leaf (Experiment)</span></div>
        </div>
      </div>

      <!-- Main Content Area -->
      <div class="tree-content-area">
        <!-- Interactive Tree View -->
        <div id="tree-interactive-view" class="tree-view-container active">
          <div id="tree-paper-0" class="tree-paper-content active"></div>
          <div id="tree-paper-1" class="tree-paper-content"></div>
          <div id="tree-paper-2" class="tree-paper-content"></div>
        </div>

        <!-- Visual Diagram View -->
        <div id="tree-diagram-view" class="tree-view-container">
          <div id="tree-diagram-0" class="tree-diagram-content active">
            <!-- Lost in the Middle SVG Diagram -->
            <div class="tree-diagram-wrapper">
              <svg viewBox="0 0 1100 750" class="tree-svg-diagram">
                <defs>
                  <linearGradient id="rootGradient" x1="0%" y1="0%" x2="100%" y2="100%">
                    <stop offset="0%" style="stop-color:#8b5cf6"/>
                    <stop offset="100%" style="stop-color:#a78bfa"/>
                  </linearGradient>
                  <linearGradient id="branch1Gradient" x1="0%" y1="0%" x2="100%" y2="100%">
                    <stop offset="0%" style="stop-color:#3b82f6"/>
                    <stop offset="100%" style="stop-color:#60a5fa"/>
                  </linearGradient>
                  <linearGradient id="branch2Gradient" x1="0%" y1="0%" x2="100%" y2="100%">
                    <stop offset="0%" style="stop-color:#10b981"/>
                    <stop offset="100%" style="stop-color:#34d399"/>
                  </linearGradient>
                  <linearGradient id="branch3Gradient" x1="0%" y1="0%" x2="100%" y2="100%">
                    <stop offset="0%" style="stop-color:#f59e0b"/>
                    <stop offset="100%" style="stop-color:#fbbf24"/>
                  </linearGradient>
                  <linearGradient id="branch4Gradient" x1="0%" y1="0%" x2="100%" y2="100%">
                    <stop offset="0%" style="stop-color:#ec4899"/>
                    <stop offset="100%" style="stop-color:#f472b6"/>
                  </linearGradient>
                </defs>
                <!-- Branch Lines from Root to Depth-1 -->
                <path d="M 550 90 C 550 130, 140 130, 140 170" stroke="#3b82f6" stroke-width="3" fill="none"/>
                <path d="M 550 90 C 550 130, 400 130, 400 170" stroke="#10b981" stroke-width="3" fill="none"/>
                <path d="M 550 90 C 550 130, 700 130, 700 170" stroke="#f59e0b" stroke-width="3" fill="none"/>
                <path d="M 550 90 C 550 130, 960 130, 960 170" stroke="#ec4899" stroke-width="3" fill="none"/>
                <!-- Branch 1 Lines to Leaves -->
                <path d="M 140 230 C 140 270, 75 270, 75 310" stroke="#3b82f6" stroke-width="2" fill="none"/>
                <path d="M 140 230 C 140 270, 140 270, 140 310" stroke="#3b82f6" stroke-width="2" fill="none"/>
                <path d="M 140 230 C 140 270, 205 270, 205 310" stroke="#3b82f6" stroke-width="2" fill="none"/>
                <!-- Branch 2 Line to Leaf -->
                <path d="M 400 230 C 400 270, 400 270, 400 310" stroke="#10b981" stroke-width="2" fill="none"/>
                <!-- Branch 3 Lines to Leaves -->
                <path d="M 700 230 C 700 270, 615 270, 615 310" stroke="#f59e0b" stroke-width="2" fill="none"/>
                <path d="M 700 230 C 700 270, 750 270, 750 310" stroke="#f59e0b" stroke-width="2" fill="none"/>
                <path d="M 700 230 C 700 270, 885 270, 885 310" stroke="#f59e0b" stroke-width="2" fill="none"/>
                <!-- Branch 4 Line to Leaf -->
                <path d="M 960 230 C 960 270, 1020 270, 1020 310" stroke="#ec4899" stroke-width="2" fill="none"/>
                <!-- Root Node -->
                <g transform="translate(150, 10)">
                  <rect width="800" height="80" fill="url(#rootGradient)" rx="14"/>
                  <text fill="#ffffff" font-size="16" font-weight="600" x="400" y="26" text-anchor="middle">Research Question</text>
                  <text x="400" y="46" text-anchor="middle" fill="#f5f3ff" font-size="12">Do LLMs robustly use information anywhere in long contexts,</text>
                  <text x="400" y="64" text-anchor="middle" fill="#f5f3ff" font-size="12">or does performance depend on where relevant content appears?</text>
                </g>
                <!-- Branch 1: Multi-Document QA -->
                <g transform="translate(15, 170)">
                  <rect width="250" height="60" fill="url(#branch1Gradient)" rx="10"/>
                  <text x="125" y="24" text-anchor="middle" font-size="10" fill="#ffffff" font-weight="600">Multi-document QA evaluation</text>
                  <text x="125" y="42" text-anchor="middle" font-size="10" fill="#eff6ff">controlled position &amp; context length</text>
                </g>
                <!-- Branch 2: Key-Value Retrieval -->
                <g transform="translate(280, 170)">
                  <rect width="240" height="60" fill="url(#branch2Gradient)" rx="10"/>
                  <text x="120" y="24" text-anchor="middle" font-size="10" fill="#ffffff" font-weight="600">Synthetic key-value retrieval</text>
                  <text x="120" y="42" text-anchor="middle" font-size="10" fill="#ecfdf5">minimal retrieval ability test</text>
                </g>
                <!-- Branch 3: Factor Analyses -->
                <g transform="translate(535, 170)">
                  <rect width="330" height="60" fill="url(#branch3Gradient)" rx="10"/>
                  <text x="165" y="24" text-anchor="middle" font-size="10" fill="#ffffff" font-weight="600">Why the position sensitivity? Factor analyses</text>
                  <text x="165" y="42" text-anchor="middle" font-size="10" fill="#fef3c7">Architecture, query placement, instruction tuning</text>
                </g>
                <!-- Branch 4: Practical Implication -->
                <g transform="translate(880, 170)">
                  <rect width="160" height="60" fill="url(#branch4Gradient)" rx="10"/>
                  <text x="80" y="24" text-anchor="middle" font-size="10" fill="#ffffff" font-weight="600">Practical implication</text>
                  <text x="80" y="42" text-anchor="middle" font-size="10" fill="#fce7f3">Open-domain QA</text>
                </g>
                <!-- Branch 1 Leaves -->
                <g transform="translate(10, 310)">
                  <rect width="130" height="80" fill="#ffffff" stroke="#3b82f6" stroke-width="2" rx="8"/>
                  <text fill="#1e293b" font-size="10" x="65" y="18" text-anchor="middle" font-weight="600">Position effects</text>
                  <text fill="#64748b" font-size="9" x="65" y="34" text-anchor="middle">10/20/30 documents</text>
                  <text fill="#64748b" font-size="9" x="65" y="48" text-anchor="middle">6 LLMs tested</text>
                  <text fill="#2563eb" font-size="10" font-weight="600" x="65" y="68" text-anchor="middle">‚Üí U-shaped curve</text>
                </g>
                <g transform="translate(145, 310)">
                  <rect width="130" height="80" fill="#ffffff" stroke="#3b82f6" stroke-width="2" rx="8"/>
                  <text fill="#1e293b" font-size="10" x="65" y="18" text-anchor="middle" font-weight="600">Baselines</text>
                  <text fill="#64748b" font-size="9" x="65" y="34" text-anchor="middle">Closed-book &amp; Oracle</text>
                  <text fill="#64748b" font-size="9" x="65" y="48" text-anchor="middle">56% vs 88%</text>
                  <text fill="#2563eb" font-size="10" font-weight="600" x="65" y="68" text-anchor="middle">‚Üí Set ceiling</text>
                </g>
                <!-- Branch 2 Leaf -->
                <g transform="translate(335, 310)">
                  <rect width="130" height="80" fill="#ffffff" stroke="#10b981" stroke-width="2" rx="8"/>
                  <text fill="#1e293b" font-size="10" x="65" y="18" text-anchor="middle" font-weight="600">UUID key-value</text>
                  <text fill="#64748b" font-size="9" x="65" y="34" text-anchor="middle">k = 75, 140, 300</text>
                  <text fill="#64748b" font-size="9" x="65" y="48" text-anchor="middle">Claude perfect</text>
                  <text fill="#059669" font-size="10" font-weight="600" x="65" y="68" text-anchor="middle">‚Üí Same U-shape</text>
                </g>
                <!-- Branch 3 Leaves -->
                <g transform="translate(550, 310)">
                  <rect width="130" height="80" fill="#ffffff" stroke="#f59e0b" stroke-width="2" rx="8"/>
                  <text fill="#1e293b" font-size="10" x="65" y="18" text-anchor="middle" font-weight="600">Architecture</text>
                  <text fill="#64748b" font-size="9" x="65" y="34" text-anchor="middle">Enc-Dec vs Dec</text>
                  <text fill="#64748b" font-size="9" x="65" y="48" text-anchor="middle">Flan-UL2/T5</text>
                  <text fill="#d97706" font-size="10" font-weight="600" x="65" y="68" text-anchor="middle">‚Üí Train len key</text>
                </g>
                <g transform="translate(685, 310)">
                  <rect width="130" height="80" fill="#ffffff" stroke="#f59e0b" stroke-width="2" rx="8"/>
                  <text fill="#1e293b" font-size="10" x="65" y="18" text-anchor="middle" font-weight="600">Query-aware</text>
                  <text fill="#64748b" font-size="9" x="65" y="34" text-anchor="middle">Query before+after</text>
                  <text fill="#64748b" font-size="9" x="65" y="48" text-anchor="middle">Helps KV, not QA</text>
                  <text fill="#d97706" font-size="10" font-weight="600" x="65" y="68" text-anchor="middle">‚Üí Partial fix</text>
                </g>
                <g transform="translate(820, 310)">
                  <rect width="130" height="80" fill="#ffffff" stroke="#f59e0b" stroke-width="2" rx="8"/>
                  <text fill="#1e293b" font-size="10" x="65" y="18" text-anchor="middle" font-weight="600">Instruction tuning</text>
                  <text fill="#64748b" font-size="9" x="65" y="34" text-anchor="middle">MPT, Llama-2</text>
                  <text fill="#64748b" font-size="9" x="65" y="48" text-anchor="middle">SFT+RLHF</text>
                  <text fill="#d97706" font-size="10" font-weight="600" x="65" y="68" text-anchor="middle">‚Üí Doesn't fix</text>
                </g>
                <!-- Branch 4 Leaf -->
                <g transform="translate(955, 310)">
                  <rect width="130" height="80" fill="#ffffff" stroke="#ec4899" stroke-width="2" rx="8"/>
                  <text fill="#1e293b" font-size="10" x="65" y="18" text-anchor="middle" font-weight="600">Reader accuracy</text>
                  <text fill="#64748b" font-size="9" x="65" y="34" text-anchor="middle">vs # docs (5-50)</text>
                  <text fill="#64748b" font-size="9" x="65" y="48" text-anchor="middle">Contriever retr.</text>
                  <text fill="#db2777" font-size="10" font-weight="600" x="65" y="68" text-anchor="middle">‚Üí Saturates early</text>
                </g>
                <!-- Findings Summary Boxes -->
                <g transform="translate(15, 415)">
                  <rect width="260" height="70" fill="rgba(59, 130, 246, 0.1)" stroke="#3b82f6" stroke-width="2" rx="10"/>
                  <text fill="#1d4ed8" font-size="12" font-weight="600" x="130" y="22" text-anchor="middle">Finding: U-Shaped Accuracy</text>
                  <text fill="#1e40af" font-size="10" x="130" y="40" text-anchor="middle">Best at beginning/end of context</text>
                  <text fill="#1e40af" font-size="10" x="130" y="56" text-anchor="middle">Worst when info is in the middle</text>
                </g>
                <g transform="translate(285, 415)">
                  <rect width="260" height="70" fill="rgba(16, 185, 129, 0.1)" stroke="#10b981" stroke-width="2" rx="10"/>
                  <text fill="#047857" font-size="12" font-weight="600" x="130" y="22" text-anchor="middle">Finding: Not Just NL Semantics</text>
                  <text fill="#065f46" font-size="10" x="130" y="40" text-anchor="middle">Even exact-match retrieval fails</text>
                  <text fill="#065f46" font-size="10" x="130" y="56" text-anchor="middle">mid-context (except Claude)</text>
                </g>
                <g transform="translate(555, 415)">
                  <rect width="260" height="70" fill="rgba(245, 158, 11, 0.1)" stroke="#f59e0b" stroke-width="2" rx="10"/>
                  <text fill="#b45309" font-size="12" font-weight="600" x="130" y="22" text-anchor="middle">Finding: Hard to Fix</text>
                  <text fill="#92400e" font-size="10" x="130" y="40" text-anchor="middle">Architecture, tuning, query placement</text>
                  <text fill="#92400e" font-size="10" x="130" y="56" text-anchor="middle">don't fully solve the problem</text>
                </g>
                <g transform="translate(825, 415)">
                  <rect width="260" height="70" fill="rgba(236, 72, 153, 0.1)" stroke="#ec4899" stroke-width="2" rx="10"/>
                  <text fill="#be185d" font-size="12" font-weight="600" x="130" y="22" text-anchor="middle">Finding: Diminishing Returns</text>
                  <text fill="#9d174d" font-size="10" x="130" y="40" text-anchor="middle">More docs ‚â† better reader accuracy</text>
                  <text fill="#9d174d" font-size="10" x="130" y="56" text-anchor="middle">Consider reranking instead</text>
                </g>
                <!-- Main Takeaway -->
                <g transform="translate(210, 510)">
                  <rect width="680" height="60" fill="rgba(139, 92, 246, 0.12)" stroke="#8b5cf6" stroke-width="2" rx="12"/>
                  <text fill="#7c3aed" font-size="15" font-weight="700" x="340" y="24" text-anchor="middle">Key Insight: The "Lost in the Middle" Effect</text>
                  <text fill="#6d28d9" font-size="12" x="340" y="44" text-anchor="middle">LLMs struggle to use information in the middle of long contexts;</text>
                  <text fill="#6d28d9" font-size="12" x="340" y="58" text-anchor="middle">this persists across architectures, tuning methods, and tasks</text>
                </g>
              </svg>
            </div>
          </div>
          <div id="tree-diagram-1" class="tree-diagram-content">
            <!-- LLMs Cannot Self-Correct SVG Diagram -->
            <div class="tree-diagram-wrapper">
              <svg viewBox="0 0 1200 720" class="tree-svg-diagram">
                <defs>
                  <linearGradient id="rootGradient2" x1="0%" y1="0%" x2="100%" y2="100%">
                    <stop offset="0%" style="stop-color:#8b5cf6"/>
                    <stop offset="100%" style="stop-color:#a78bfa"/>
                  </linearGradient>
                  <linearGradient id="branch1Gradient2" x1="0%" y1="0%" x2="100%" y2="100%">
                    <stop offset="0%" style="stop-color:#3b82f6"/>
                    <stop offset="100%" style="stop-color:#60a5fa"/>
                  </linearGradient>
                  <linearGradient id="branch2Gradient2" x1="0%" y1="0%" x2="100%" y2="100%">
                    <stop offset="0%" style="stop-color:#10b981"/>
                    <stop offset="100%" style="stop-color:#34d399"/>
                  </linearGradient>
                  <linearGradient id="branch3Gradient2" x1="0%" y1="0%" x2="100%" y2="100%">
                    <stop offset="0%" style="stop-color:#f59e0b"/>
                    <stop offset="100%" style="stop-color:#fbbf24"/>
                  </linearGradient>
                </defs>
                <!-- Branch Lines from Root to Depth-1 -->
                <path d="M 600 100 C 600 150, 200 150, 200 190" stroke="#3b82f6" stroke-width="3" fill="none"/>
                <path d="M 600 100 C 600 150, 600 150, 600 190" stroke="#10b981" stroke-width="3" fill="none"/>
                <path d="M 600 100 C 600 150, 945 150, 945 190" stroke="#f59e0b" stroke-width="3" fill="none"/>
                <!-- Branch 1 Lines to Leaves -->
                <path d="M 200 260 C 200 300, 80 300, 80 340" stroke="#3b82f6" stroke-width="2" fill="none"/>
                <path d="M 200 260 C 200 300, 210 300, 210 340" stroke="#3b82f6" stroke-width="2" fill="none"/>
                <path d="M 200 260 C 200 300, 340 300, 340 340" stroke="#3b82f6" stroke-width="2" fill="none"/>
                <!-- Branch 2 Line to Leaf -->
                <path d="M 600 260 C 600 300, 600 300, 600 340" stroke="#10b981" stroke-width="2" fill="none"/>
                <!-- Branch 3 Line to Leaf -->
                <path d="M 1000 260 C 1000 300, 1000 300, 1000 340" stroke="#f59e0b" stroke-width="2" fill="none"/>
                <!-- Root Node -->
                <g transform="translate(250, 20)">
                  <rect width="700" height="80" fill="url(#rootGradient2)" rx="14"/>
                  <text fill="#ffffff" font-size="17" font-weight="600" x="350" y="28" text-anchor="middle">Research Question</text>
                  <text x="350" y="48" text-anchor="middle" fill="#f5f3ff" font-size="12">Can LLMs intrinsically self-correct their own reasoning</text>
                  <text x="350" y="66" text-anchor="middle" fill="#f5f3ff" font-size="12">without any external feedback? If not, why?</text>
                </g>
                <!-- Branch 1: Intrinsic Self-Correction -->
                <g transform="translate(20, 190)">
                  <rect width="360" height="70" fill="url(#branch1Gradient2)" rx="12"/>
                  <text x="180" y="28" text-anchor="middle" font-size="12" fill="#ffffff" font-weight="600">Establish and evaluate intrinsic</text>
                  <text x="180" y="46" text-anchor="middle" font-size="12" fill="#eff6ff" font-weight="600">self-correction for reasoning tasks</text>
                </g>
                <!-- Branch 2: Compare Alternatives -->
                <g transform="translate(475, 190)">
                  <rect width="250" height="70" fill="url(#branch2Gradient2)" rx="12"/>
                  <text x="125" y="28" text-anchor="middle" font-size="12" fill="#ffffff" font-weight="600">Compare to alternatives</text>
                  <text x="125" y="46" text-anchor="middle" font-size="12" fill="#ecfdf5" font-weight="600">at matched inference cost</text>
                </g>
                <!-- Branch 3: Prompt Confounds -->
                <g transform="translate(820, 190)">
                  <rect width="250" height="70" fill="url(#branch3Gradient2)" rx="12"/>
                  <text x="125" y="28" text-anchor="middle" font-size="12" fill="#ffffff" font-weight="600">Disentangle prompt-design</text>
                  <text x="125" y="46" text-anchor="middle" font-size="12" fill="#fef3c7" font-weight="600">confounds in evaluations</text>
                </g>
                <!-- Branch 1 Leaves -->
                <g transform="translate(10, 340)">
                  <rect width="140" height="95" fill="#ffffff" stroke="#3b82f6" stroke-width="2" rx="8"/>
                  <text fill="#1e293b" font-size="10" x="70" y="22" text-anchor="middle" font-weight="600">Oracle-gated</text>
                  <text fill="#1e293b" font-size="10" x="70" y="38" text-anchor="middle">Self-Correction</text>
                  <text fill="#64748b" font-size="9" x="70" y="56" text-anchor="middle">GSM8K: 75.9‚Üí84.3</text>
                  <text fill="#2563eb" font-size="10" font-weight="600" x="70" y="78" text-anchor="middle">‚Üí Needs labels</text>
                </g>
                <g transform="translate(160, 340)">
                  <rect width="140" height="95" fill="#ffffff" stroke="#3b82f6" stroke-width="2" rx="8"/>
                  <text fill="#1e293b" font-size="10" x="70" y="22" text-anchor="middle" font-weight="600">Intrinsic on</text>
                  <text fill="#1e293b" font-size="10" x="70" y="38" text-anchor="middle">GPT-3.5/4/Llama</text>
                  <text fill="#64748b" font-size="9" x="70" y="56" text-anchor="middle">GSM8K: 75.9‚Üí74.7</text>
                  <text fill="#dc2626" font-size="10" font-weight="600" x="70" y="78" text-anchor="middle">‚Üí Performance drops</text>
                </g>
                <g transform="translate(310, 340)">
                  <rect width="140" height="95" fill="#ffffff" stroke="#3b82f6" stroke-width="2" rx="8"/>
                  <text fill="#1e293b" font-size="10" x="70" y="22" text-anchor="middle" font-weight="600">Behavioral</text>
                  <text fill="#1e293b" font-size="10" x="70" y="38" text-anchor="middle">Analysis</text>
                  <text fill="#64748b" font-size="9" x="70" y="56" text-anchor="middle">Answer changes</text>
                  <text fill="#2563eb" font-size="10" font-weight="600" x="70" y="78" text-anchor="middle">‚Üí Correct‚ÜíWrong</text>
                </g>
                <!-- Branch 2 Leaf -->
                <g transform="translate(500, 340)">
                  <rect width="200" height="95" fill="#ffffff" stroke="#10b981" stroke-width="2" rx="8"/>
                  <text fill="#1e293b" font-size="11" x="100" y="22" text-anchor="middle" font-weight="600">Multi-Agent Debate</text>
                  <text fill="#1e293b" font-size="11" x="100" y="38" text-anchor="middle">vs Self-Consistency</text>
                  <text fill="#64748b" font-size="10" x="100" y="56" text-anchor="middle">GSM8K, 3/6/9 responses</text>
                  <text fill="#059669" font-size="11" font-weight="600" x="100" y="78" text-anchor="middle">‚Üí SC wins at same cost</text>
                </g>
                <!-- Branch 3 Leaf -->
                <g transform="translate(845, 340)">
                  <rect width="200" height="95" fill="#ffffff" stroke="#f59e0b" stroke-width="2" rx="8"/>
                  <text fill="#1e293b" font-size="11" x="100" y="22" text-anchor="middle" font-weight="600">CommonGen-Hard</text>
                  <text fill="#1e293b" font-size="11" x="100" y="38" text-anchor="middle">Improved Prompt</text>
                  <text fill="#64748b" font-size="10" x="100" y="56" text-anchor="middle">Standard: 81.8 vs SC: 75.1</text>
                  <text fill="#d97706" font-size="11" font-weight="600" x="100" y="78" text-anchor="middle">‚Üí Better prompt wins</text>
                </g>
                <!-- Findings Summary Boxes -->
                <g transform="translate(20, 460)">
                  <rect width="350" height="80" fill="rgba(59, 130, 246, 0.1)" stroke="#3b82f6" stroke-width="2" rx="10"/>
                  <text fill="#1d4ed8" font-size="14" font-weight="600" x="175" y="26" text-anchor="middle">Finding: Self-Correction Fails</text>
                  <text fill="#1e40af" font-size="12" x="175" y="46" text-anchor="middle">Without external feedback, LLMs cannot</text>
                  <text fill="#1e40af" font-size="12" x="175" y="64" text-anchor="middle">reliably self-correct reasoning</text>
                </g>
                <g transform="translate(390, 460)">
                  <rect width="350" height="80" fill="rgba(16, 185, 129, 0.1)" stroke="#10b981" stroke-width="2" rx="10"/>
                  <text fill="#047857" font-size="14" font-weight="600" x="175" y="26" text-anchor="middle">Finding: Simpler Methods Work</text>
                  <text fill="#065f46" font-size="12" x="175" y="46" text-anchor="middle">Self-consistency beats debate</text>
                  <text fill="#065f46" font-size="12" x="175" y="64" text-anchor="middle">at matched inference cost</text>
                </g>
                <g transform="translate(760, 460)">
                  <rect width="350" height="80" fill="rgba(245, 158, 11, 0.1)" stroke="#f59e0b" stroke-width="2" rx="10"/>
                  <text fill="#b45309" font-size="14" font-weight="600" x="175" y="26" text-anchor="middle">Finding: Prompt Confounds</text>
                  <text fill="#92400e" font-size="12" x="175" y="46" text-anchor="middle">Prior gains from weak initial prompts,</text>
                  <text fill="#92400e" font-size="12" x="175" y="64" text-anchor="middle">not true self-correction ability</text>
                </g>
                <!-- Main Takeaway -->
                <g transform="translate(260, 565)">
                  <rect width="680" height="70" fill="rgba(220, 38, 38, 0.12)" stroke="#dc2626" stroke-width="2" rx="12"/>
                  <text fill="#b91c1c" font-size="16" font-weight="700" x="340" y="28" text-anchor="middle">Key Insight: No Intrinsic Self-Correction</text>
                  <text fill="#991b1b" font-size="13" x="340" y="48" text-anchor="middle">LLMs cannot self-correct reasoning without external feedback;</text>
                  <text fill="#991b1b" font-size="13" x="340" y="66" text-anchor="middle">they often change correct answers to incorrect ones</text>
                </g>
              </svg>
            </div>
          </div>
          <div id="tree-diagram-2" class="tree-diagram-content">
            <!-- Racial Bias in Medical Reports SVG Diagram -->
            <div class="tree-diagram-wrapper">
              <svg viewBox="0 0 1100 640" class="tree-svg-diagram">
                <defs>
                  <linearGradient id="rootGradient3" x1="0%" y1="0%" x2="100%" y2="100%">
                    <stop offset="0%" style="stop-color:#8b5cf6"/>
                    <stop offset="100%" style="stop-color:#a78bfa"/>
                  </linearGradient>
                  <linearGradient id="branch1Gradient3" x1="0%" y1="0%" x2="100%" y2="100%">
                    <stop offset="0%" style="stop-color:#3b82f6"/>
                    <stop offset="100%" style="stop-color:#60a5fa"/>
                  </linearGradient>
                  <linearGradient id="branch2Gradient3" x1="0%" y1="0%" x2="100%" y2="100%">
                    <stop offset="0%" style="stop-color:#10b981"/>
                    <stop offset="100%" style="stop-color:#34d399"/>
                  </linearGradient>
                  <linearGradient id="branch3Gradient3" x1="0%" y1="0%" x2="100%" y2="100%">
                    <stop offset="0%" style="stop-color:#f59e0b"/>
                    <stop offset="100%" style="stop-color:#fbbf24"/>
                  </linearGradient>
                  <linearGradient id="branch4Gradient3" x1="0%" y1="0%" x2="100%" y2="100%">
                    <stop offset="0%" style="stop-color:#ec4899"/>
                    <stop offset="100%" style="stop-color:#f472b6"/>
                  </linearGradient>
                </defs>
                <!-- Branch Lines from Root to Depth-1 -->
                <path d="M 550 90 C 550 130, 140 130, 140 165" stroke="#3b82f6" stroke-width="3" fill="none"/>
                <path d="M 550 90 C 550 130, 410 130, 410 165" stroke="#10b981" stroke-width="3" fill="none"/>
                <path d="M 550 90 C 550 130, 690 130, 690 165" stroke="#f59e0b" stroke-width="3" fill="none"/>
                <path d="M 550 90 C 550 130, 960 130, 960 165" stroke="#ec4899" stroke-width="3" fill="none"/>
                <!-- Branch 1 Lines to Leaves -->
                <path d="M 140 225 C 140 255, 75 255, 75 285" stroke="#3b82f6" stroke-width="2" fill="none"/>
                <path d="M 140 225 C 140 255, 205 255, 205 285" stroke="#3b82f6" stroke-width="2" fill="none"/>
                <!-- Branch 2 Lines to Leaves -->
                <path d="M 410 225 C 410 255, 345 255, 345 285" stroke="#10b981" stroke-width="2" fill="none"/>
                <path d="M 410 225 C 410 255, 475 255, 475 285" stroke="#10b981" stroke-width="2" fill="none"/>
                <!-- Branch 3 Lines to Leaves -->
                <path d="M 690 225 C 690 255, 625 255, 625 285" stroke="#f59e0b" stroke-width="2" fill="none"/>
                <path d="M 690 225 C 690 255, 755 255, 755 285" stroke="#f59e0b" stroke-width="2" fill="none"/>
                <!-- Branch 4 Lines to Leaves -->
                <path d="M 960 225 C 960 255, 895 255, 895 285" stroke="#ec4899" stroke-width="2" fill="none"/>
                <path d="M 960 225 C 960 255, 1025 255, 1025 285" stroke="#ec4899" stroke-width="2" fill="none"/>
                <!-- Root Node -->
                <g transform="translate(150, 10)">
                  <rect width="800" height="80" fill="url(#rootGradient3)" rx="14"/>
                  <text fill="#ffffff" font-size="16" font-weight="600" x="400" y="26" text-anchor="middle">Research Question</text>
                  <text x="400" y="46" text-anchor="middle" fill="#f5f3ff" font-size="12">Do LLMs (GPT-3.5, GPT-4) exhibit racial/ethnic bias when</text>
                  <text x="400" y="64" text-anchor="middle" fill="#f5f3ff" font-size="12">generating medical case reports? How can such bias be quantified?</text>
                </g>
                <!-- Branch 1: Bias-Probing Framework -->
                <g transform="translate(15, 165)">
                  <rect width="250" height="60" fill="url(#branch1Gradient3)" rx="10"/>
                  <text x="125" y="24" text-anchor="middle" font-size="10" fill="#ffffff" font-weight="600">Design controlled bias-probing</text>
                  <text x="125" y="42" text-anchor="middle" font-size="10" fill="#eff6ff" font-weight="600">framework (race injection)</text>
                </g>
                <!-- Branch 2: Diagnosis Bias -->
                <g transform="translate(280, 165)">
                  <rect width="250" height="60" fill="url(#branch2Gradient3)" rx="10"/>
                  <text x="125" y="24" text-anchor="middle" font-size="10" fill="#ffffff" font-weight="600">Racial bias in diagnosis</text>
                  <text x="125" y="42" text-anchor="middle" font-size="10" fill="#ecfdf5" font-weight="600">and patient info processing</text>
                </g>
                <!-- Branch 3: Cost/Hospitalization -->
                <g transform="translate(545, 165)">
                  <rect width="260" height="60" fill="url(#branch3Gradient3)" rx="10"/>
                  <text x="130" y="24" text-anchor="middle" font-size="10" fill="#ffffff" font-weight="600">Quantify disparities in projected</text>
                  <text x="130" y="42" text-anchor="middle" font-size="10" fill="#fef3c7" font-weight="600">costs &amp; hospitalization durations</text>
                </g>
                <!-- Branch 4: Survival & Decisiveness -->
                <g transform="translate(835, 165)">
                  <rect width="250" height="60" fill="url(#branch4Gradient3)" rx="10"/>
                  <text x="125" y="24" text-anchor="middle" font-size="10" fill="#ffffff" font-weight="600">Survival predictions &amp;</text>
                  <text x="125" y="42" text-anchor="middle" font-size="10" fill="#fce7f3" font-weight="600">model decisiveness</text>
                </g>
                <!-- Branch 1 Leaves -->
                <g transform="translate(10, 285)">
                  <rect width="130" height="80" fill="#ffffff" stroke="#3b82f6" stroke-width="2" rx="8"/>
                  <text fill="#1e293b" font-size="9" x="65" y="16" text-anchor="middle" font-weight="600">Patient Profiles</text>
                  <text fill="#64748b" font-size="8" x="65" y="30" text-anchor="middle">PMC-Patients</text>
                  <text fill="#64748b" font-size="8" x="65" y="44" text-anchor="middle">200 cases √ó 4 races</text>
                  <text fill="#2563eb" font-size="9" font-weight="600" x="65" y="64" text-anchor="middle">‚Üí Race controlled</text>
                </g>
                <g transform="translate(150, 285)">
                  <rect width="130" height="80" fill="#ffffff" stroke="#3b82f6" stroke-width="2" rx="8"/>
                  <text fill="#1e293b" font-size="9" x="65" y="16" text-anchor="middle" font-weight="600">Report Generation</text>
                  <text fill="#64748b" font-size="8" x="65" y="30" text-anchor="middle">9-section template</text>
                  <text fill="#64748b" font-size="8" x="65" y="44" text-anchor="middle">10 gens per combo</text>
                  <text fill="#2563eb" font-size="9" font-weight="600" x="65" y="64" text-anchor="middle">‚Üí Standardized</text>
                </g>
                <!-- Branch 2 Leaves -->
                <g transform="translate(290, 285)">
                  <rect width="130" height="80" fill="#ffffff" stroke="#10b981" stroke-width="2" rx="8"/>
                  <text fill="#1e293b" font-size="9" x="65" y="16" text-anchor="middle" font-weight="600">Paraphrasing Bias</text>
                  <text fill="#64748b" font-size="8" x="65" y="30" text-anchor="middle">Fabricated details</text>
                  <text fill="#64748b" font-size="8" x="65" y="44" text-anchor="middle">16/200 biased cases</text>
                  <text fill="#059669" font-size="9" font-weight="600" x="65" y="64" text-anchor="middle">‚Üí Stereotypes added</text>
                </g>
                <g transform="translate(430, 285)">
                  <rect width="130" height="80" fill="#ffffff" stroke="#10b981" stroke-width="2" rx="8"/>
                  <text fill="#1e293b" font-size="9" x="65" y="16" text-anchor="middle" font-weight="600">Diagnosis Bias</text>
                  <text fill="#64748b" font-size="8" x="65" y="30" text-anchor="middle">Disease-race links</text>
                  <text fill="#64748b" font-size="8" x="65" y="44" text-anchor="middle">21/200 disparities</text>
                  <text fill="#059669" font-size="9" font-weight="600" x="65" y="64" text-anchor="middle">‚Üí HIV‚ÜîBlack</text>
                </g>
                <!-- Branch 3 Leaves -->
                <g transform="translate(570, 285)">
                  <rect width="130" height="80" fill="#ffffff" stroke="#f59e0b" stroke-width="2" rx="8"/>
                  <text fill="#1e293b" font-size="9" x="65" y="16" text-anchor="middle" font-weight="600">GPT-3.5 Disparities</text>
                  <text fill="#64748b" font-size="8" x="65" y="30" text-anchor="middle">Cost &amp; hospital days</text>
                  <text fill="#64748b" font-size="8" x="65" y="44" text-anchor="middle">White vs Black: 59%</text>
                  <text fill="#d97706" font-size="9" font-weight="600" x="65" y="64" text-anchor="middle">‚Üí Higher for White</text>
                </g>
                <g transform="translate(710, 285)">
                  <rect width="130" height="80" fill="#ffffff" stroke="#f59e0b" stroke-width="2" rx="8"/>
                  <text fill="#1e293b" font-size="9" x="65" y="16" text-anchor="middle" font-weight="600">GPT-4 Disparities</text>
                  <text fill="#64748b" font-size="8" x="65" y="30" text-anchor="middle">More balanced cost</text>
                  <text fill="#64748b" font-size="8" x="65" y="44" text-anchor="middle">Similar hosp. trend</text>
                  <text fill="#d97706" font-size="9" font-weight="600" x="65" y="64" text-anchor="middle">‚Üí Partially mitigated</text>
                </g>
                <!-- Branch 4 Leaves -->
                <g transform="translate(850, 285)">
                  <rect width="130" height="80" fill="#ffffff" stroke="#ec4899" stroke-width="2" rx="8"/>
                  <text fill="#1e293b" font-size="9" x="65" y="16" text-anchor="middle" font-weight="600">Survival Prediction</text>
                  <text fill="#64748b" font-size="8" x="65" y="30" text-anchor="middle">200 deceased cases</text>
                  <text fill="#64748b" font-size="8" x="65" y="44" text-anchor="middle">GPT-4: 29% accuracy</text>
                  <text fill="#db2777" font-size="9" font-weight="600" x="65" y="64" text-anchor="middle">‚Üí Overly optimistic</text>
                </g>
                <g transform="translate(990, 285)">
                  <rect width="100" height="80" fill="#ffffff" stroke="#ec4899" stroke-width="2" rx="8"/>
                  <text fill="#1e293b" font-size="9" x="50" y="16" text-anchor="middle" font-weight="600">Decisiveness</text>
                  <text fill="#64748b" font-size="8" x="50" y="30" text-anchor="middle">Inconclusive rates</text>
                  <text fill="#64748b" font-size="8" x="50" y="44" text-anchor="middle">GPT-4: 29-38%</text>
                  <text fill="#db2777" font-size="9" font-weight="600" x="50" y="64" text-anchor="middle">‚Üí More hedging</text>
                </g>
                <!-- Findings Summary Boxes -->
                <g transform="translate(15, 390)">
                  <rect width="250" height="65" fill="rgba(59, 130, 246, 0.1)" stroke="#3b82f6" stroke-width="2" rx="10"/>
                  <text fill="#1d4ed8" font-size="11" font-weight="600" x="125" y="20" text-anchor="middle">Finding: Stereotyped Content</text>
                  <text fill="#1e40af" font-size="9" x="125" y="38" text-anchor="middle">LLMs add fabricated racial details</text>
                  <text fill="#1e40af" font-size="9" x="125" y="52" text-anchor="middle">to patient descriptions</text>
                </g>
                <g transform="translate(285, 390)">
                  <rect width="250" height="65" fill="rgba(16, 185, 129, 0.1)" stroke="#10b981" stroke-width="2" rx="10"/>
                  <text fill="#047857" font-size="11" font-weight="600" x="125" y="20" text-anchor="middle">Finding: Disease-Race Links</text>
                  <text fill="#065f46" font-size="9" x="125" y="38" text-anchor="middle">Diagnoses reflect stereotyped</text>
                  <text fill="#065f46" font-size="9" x="125" y="52" text-anchor="middle">race-disease associations</text>
                </g>
                <g transform="translate(555, 390)">
                  <rect width="250" height="65" fill="rgba(245, 158, 11, 0.1)" stroke="#f59e0b" stroke-width="2" rx="10"/>
                  <text fill="#b45309" font-size="11" font-weight="600" x="125" y="20" text-anchor="middle">Finding: Cost Disparities</text>
                  <text fill="#92400e" font-size="9" x="125" y="38" text-anchor="middle">Higher costs/stays predicted</text>
                  <text fill="#92400e" font-size="9" x="125" y="52" text-anchor="middle">more often for White patients</text>
                </g>
                <g transform="translate(825, 390)">
                  <rect width="250" height="65" fill="rgba(236, 72, 153, 0.1)" stroke="#ec4899" stroke-width="2" rx="10"/>
                  <text fill="#be185d" font-size="11" font-weight="600" x="125" y="20" text-anchor="middle">Finding: GPT-4 Trade-off</text>
                  <text fill="#9d174d" font-size="9" x="125" y="38" text-anchor="middle">Fairer but less conclusive,</text>
                  <text fill="#9d174d" font-size="9" x="125" y="52" text-anchor="middle">overly optimistic on survival</text>
                </g>
                <!-- Main Takeaway -->
                <g transform="translate(210, 480)">
                  <rect width="680" height="65" fill="rgba(220, 38, 38, 0.12)" stroke="#dc2626" stroke-width="2" rx="12"/>
                  <text fill="#b91c1c" font-size="14" font-weight="700" x="340" y="24" text-anchor="middle">Key Insight: Racial Bias in Medical LLMs</text>
                  <text fill="#991b1b" font-size="11" x="340" y="44" text-anchor="middle">GPT-3.5 and GPT-4 exhibit measurable racial biases in medical reports;</text>
                  <text fill="#991b1b" font-size="11" x="340" y="60" text-anchor="middle">GPT-4 is fairer but hedges more and shows unrealistic optimism</text>
                </g>
              </svg>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- 6. ERROR ANALYSIS SECTION -->
<section class="section analysis-section" id="analysis">
  <div class="container is-max-desktop">
    <h2 class="title is-3 section-title has-text-centered">Error Analysis</h2>
    <p class="section-subtitle has-text-centered">
      Where do AI research agents fail? Our taxonomy reveals systematic failure patterns.
    </p>

    <div class="error-summary-grid">
      <div class="error-phase-card planning">
        <div class="phase-icon">üìã</div>
        <h4>Planning</h4>
        <div class="phase-percentage">73.6%</div>
        <ul class="phase-errors">
          <li>Goal Deviation</li>
          <li>Method Deviation</li>
        </ul>
      </div>

      <div class="error-phase-card implementation">
        <div class="phase-icon">üíª</div>
        <h4>Implementation</h4>
        <div class="phase-percentage">3.0%</div>
        <ul class="phase-errors">
          <li>Unsound Code</li>
          <li>Missing Steps</li>
          <li>Wrong Dependencies</li>
        </ul>
      </div>

      <div class="error-phase-card execution">
        <div class="phase-icon">‚ö°</div>
        <h4>Execution</h4>
        <div class="phase-percentage">5.6%</div>
        <ul class="phase-errors">
          <li>Premature Termination</li>
          <li>Endless Loop</li>
          <li>Runtime Errors</li>
        </ul>
      </div>

      <div class="error-phase-card analysis">
        <div class="phase-icon">üî¨</div>
        <h4>Analysis</h4>
        <div class="phase-percentage">17.8%</div>
        <ul class="phase-errors">
          <li>Misinterpretation</li>
          <li>Overgeneralization</li>
          <li>Unrelated Conclusions</li>
        </ul>
      </div>
    </div>

    <div class="analysis-insight">
      <p><strong>Key Insight:</strong> The challenge is scientific reasoning, not implementation. As models become more capable, the bottleneck shifts from coding to high-level planning and analysis.</p>
    </div>
  </div>
</section>


<!-- 7. BIBTEX SECTION -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title section-title has-text-centered">Citation</h2>
    <p class="has-text-centered" style="color: var(--text-secondary); margin-bottom: 1.5rem;">
      Paper coming soon. Citation will be available upon publication.
    </p>
    <pre><code>@article{firebench2026,
  title     = {FIRE-Bench: Evaluating Research Agents on the Rediscovery of Scientific Insights},
  author    = {Wang, Zhen and Bai, Fan and Luo, Zhongyan and Su, Jinyan and Sun, Kaiser and Yu, Xinle and Liu, Jieyuan and Zhou, Kun and Cardie, Claire and Dredze, Mark and Xing, Eric P. and Hu, Zhiting},
  journal   = {arXiv preprint},
  year      = {2026},
  note      = {Coming Soon}
}</code></pre>
  </div>
</section>


<!-- INSTITUTION LOGOS -->
<section class="section institution-section">
  <div class="container is-max-desktop">
    <div class="institution-logos">
      <a href="https://ucsd.edu" target="_blank" class="institution-logo">
        <img src="./static/images/institutions/ucsd.svg" alt="UC San Diego">
      </a>
      <a href="https://www.jhu.edu" target="_blank" class="institution-logo">
        <img src="./static/images/institutions/jhu.svg" alt="Johns Hopkins University">
      </a>
      <a href="https://www.cornell.edu" target="_blank" class="institution-logo">
        <img src="./static/images/institutions/cornell.svg" alt="Cornell University">
      </a>
      <a href="https://mbzuai.ac.ae" target="_blank" class="institution-logo">
        <img src="./static/images/institutions/mbzuai.png" alt="MBZUAI">
      </a>
    </div>
  </div>
</section>


<!-- FOOTER -->
<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content has-text-centered">
          <p>
            Template from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Scripts -->
<script>
document.addEventListener('DOMContentLoaded', function() {
  // Navbar scroll effect
  const navbar = document.querySelector('.main-nav');
  window.addEventListener('scroll', function() {
    if (window.scrollY > 50) {
      navbar.classList.add('scrolled');
    } else {
      navbar.classList.remove('scrolled');
    }
  });

  // Mobile burger menu toggle
  const burger = document.querySelector('.navbar-burger');
  const menu = document.querySelector('#mainNavbar');
  if (burger && menu) {
    burger.addEventListener('click', function() {
      burger.classList.toggle('is-active');
      menu.classList.toggle('is-active');
    });
  }

  // Close mobile menu when clicking a link
  const navLinks = document.querySelectorAll('.navbar-menu .navbar-item');
  navLinks.forEach(link => {
    link.addEventListener('click', function() {
      burger.classList.remove('is-active');
      menu.classList.remove('is-active');
    });
  });

  // Task filter functionality
  const filterButtons = document.querySelectorAll('.task-filter');
  const taskCards = document.querySelectorAll('.task-card-expandable');
  const tasksGrid = document.querySelector('.tasks-grid-interactive');
  
  // Create the full-width details panel
  const detailsPanel = document.createElement('div');
  detailsPanel.className = 'task-details-panel';
  detailsPanel.innerHTML = `
    <div class="task-details-panel-header">
      <div class="task-details-panel-title">
        <span class="panel-venue-tag"></span>
        <h3></h3>
      </div>
      <button class="task-details-panel-close">&times;</button>
    </div>
    <div class="task-details-panel-content"></div>
  `;
  
  // Close button functionality
  detailsPanel.querySelector('.task-details-panel-close').addEventListener('click', function() {
    detailsPanel.classList.remove('active');
    taskCards.forEach(card => card.classList.remove('expanded'));
    // Remove panel from grid
    if (detailsPanel.parentNode) {
      detailsPanel.parentNode.removeChild(detailsPanel);
    }
  });

  // Initialize: show only featured papers (for "All" tab)
  taskCards.forEach(card => {
    if (card.getAttribute('data-featured') === 'true') {
      card.style.display = 'block';
    } else {
      card.style.display = 'none';
    }
  });

  filterButtons.forEach(button => {
    button.addEventListener('click', function() {
      // Update active button
      filterButtons.forEach(btn => btn.classList.remove('active'));
      this.classList.add('active');

      const filter = this.getAttribute('data-filter');

      // Close details panel and collapse all cards when switching tabs
      detailsPanel.classList.remove('active');
      if (detailsPanel.parentNode) {
        detailsPanel.parentNode.removeChild(detailsPanel);
      }
      taskCards.forEach(card => {
        card.classList.remove('expanded');
      });

      taskCards.forEach(card => {
        if (filter === 'all') {
          // Show only featured papers for "All" tab
          if (card.getAttribute('data-featured') === 'true') {
            card.style.display = 'block';
          } else {
            card.style.display = 'none';
          }
        } else if (card.getAttribute('data-venue') === filter) {
          card.style.display = 'block';
        } else {
          card.style.display = 'none';
        }
      });
    });
  });

  // Helper function to get number of grid columns
  function getGridColumns() {
    const width = window.innerWidth;
    if (width <= 600) return 1;
    if (width <= 900) return 2;
    return 3;
  }

  // Helper function to find the last card in the same row
  function getLastCardInRow(clickedCard) {
    // Get all currently visible cards (excluding the panel itself)
    const visibleCards = Array.from(taskCards).filter(card => 
      card.style.display !== 'none' && card !== detailsPanel
    );
    
    const columns = getGridColumns();
    const clickedIndex = visibleCards.indexOf(clickedCard);
    
    if (clickedIndex === -1) return clickedCard;
    
    // Calculate which row the clicked card is in
    const rowNumber = Math.floor(clickedIndex / columns);
    
    // Find the last card in that row
    const lastIndexInRow = Math.min((rowNumber + 1) * columns - 1, visibleCards.length - 1);
    
    return visibleCards[lastIndexInRow];
  }

  // Task card expand/collapse functionality
  taskCards.forEach(card => {
    const cardHeader = card.querySelector('.task-card-interactive');
    cardHeader.addEventListener('click', function() {
      const isExpanded = card.classList.contains('expanded');
      
      // Close other expanded cards
      taskCards.forEach(otherCard => {
        otherCard.classList.remove('expanded');
      });
      
      if (isExpanded) {
        // Close the panel and remove from grid
        detailsPanel.classList.remove('active');
        if (detailsPanel.parentNode) {
          detailsPanel.parentNode.removeChild(detailsPanel);
        }
      } else {
        // Expand this card and show panel
        card.classList.add('expanded');
        
        // Get card data
        const venue = card.querySelector('.task-venue-tag').textContent;
        const title = card.querySelector('.task-title').textContent;
        const details = card.querySelector('.task-details');
        
        // Update panel content
        detailsPanel.querySelector('.panel-venue-tag').textContent = venue;
        detailsPanel.querySelector('h3').textContent = title;
        detailsPanel.querySelector('.task-details-panel-content').innerHTML = details.innerHTML;
        
        // Remove panel first if it exists (to recalculate row positions correctly)
        if (detailsPanel.parentNode) {
          detailsPanel.parentNode.removeChild(detailsPanel);
        }
        
        // Find the last card in the same row and insert panel after it
        const lastCardInRow = getLastCardInRow(card);
        lastCardInRow.parentNode.insertBefore(detailsPanel, lastCardInRow.nextSibling);
        
        // Show panel
        detailsPanel.classList.add('active');
        
        // Scroll panel into view
        setTimeout(() => {
          detailsPanel.scrollIntoView({ behavior: 'smooth', block: 'nearest' });
        }, 100);
      }
    });
  });
});
</script>

<!-- Research Tree Visualization Script -->
<script>
const treePapers = [
    {
        paper: {
            title: "Lost in the Middle: How Language Models Use Long Contexts",
            authors: ["Nelson F. Liu", "Kevin Lin", "John Hewitt", "Ashwin Paranjape", "Michele Bevilacqua", "Fabio Petroni", "Percy Liang"],
            venue: "arXiv (preprint)",
            year: "2023"
        },
        problem_tree: {
            "node": "Root: Do current long-context language models robustly use information anywhere in their input, or does performance depend on where relevant content appears?",
            "type": "root node",
            "description": "The paper probes how language models use long contexts by manipulating context length and the position of relevant information, introducing controlled evaluations (multi-document QA and a synthetic key-value task), analyses of model/Prompt factors, and a practical case study for open-domain QA.",
            "evidence": "Abstract & Introduction summarize the goal and main finding (U-shaped performance with primacy/recency bias; degradation in the middle). See pp.1‚Äì3 and Fig.1 (p.1).",
            "children": [
                {
                    "node": "Evaluate robustness via realistic multi-document QA under controlled context length and position",
                    "type": "depth-1 node",
                    "description": "Construct a QA setup where exactly one passage contains the answer and the rest are distractors; vary the number of passages (context length) and reorder to place the answer passage at different positions.",
                    "evidence": "Task and controls detailed in Sec.2.1 with examples in Figs.2‚Äì4 (pp.3‚Äì4).",
                    "children": [
                        {
                            "node": "Controlled multi-document QA design",
                            "type": "depth-2 node",
                            "description": "Use NQ-Open queries whose long answers are paragraphs; compile one answer passage and k‚àí1 retrieved distractors; present distractors by decreasing relevance; manipulate answer passage position; vary k‚àà{10,20,30}.",
                            "evidence": "Sec.2.1 and Figs.2‚Äì4 (pp.3‚Äì4).",
                            "children": [
                                {
                                    "type": "leaf node",
                                    "task": "Effect of answer position across 10/20/30 passages in multi-document QA",
                                    "dataset": ["NaturalQuestions-Open (paragraph long-answer subset, 2,655 queries)", "Wikipedia (2018 dump)"],
                                    "model_or_method": ["GPT-3.5-Turbo (0613)", "GPT-3.5-Turbo-16k (0613)", "Claude-1.3", "Claude-1.3-100k", "MPT-30B-Instruct (ALiBi)", "LongChat-13B-16k"],
                                    "metrics": ["Accuracy (whether any gold answer string appears in the output)"],
                                    "protocol_or_setup": "Greedy decoding with a standard prompt; answer passage placed at indexed positions; distractors ordered by decreasing relevance; total docs k‚àà{10 (~2K tokens), 20 (~4K), 30 (~6K)}; see Sec.2.2 for models and prompting.",
                                    "evidence": { "figure": "Fig.5 (p.5)", "table": "Tables 5‚Äì7 (Appx. G, p.18)", "section": "Sec.2.3 (pp.5‚Äì6)" },
                                    "conclusion": "All models exhibit a U-shaped curve: highest accuracy when the answer passage is at the beginning (primacy) or end (recency) and the lowest when it is in the middle."
                                },
                                {
                                    "type": "leaf node",
                                    "task": "Closed-book and oracle baselines for multi-document QA",
                                    "dataset": ["NaturalQuestions-Open (same subset as above)"],
                                    "model_or_method": ["Same model set as above"],
                                    "metrics": ["Accuracy"],
                                    "protocol_or_setup": "Closed-book: no passages provided; Oracle: only the single gold passage provided.",
                                    "evidence": { "table": "Table 1 (p.5)", "section": "Sec.2.3 (p.5)" },
                                    "conclusion": "Closed-book vs. oracle accuracies contextualize the ceiling; e.g., GPT-3.5-Turbo: 56.1% (closed-book) vs. 88.3% (oracle)."
                                }
                            ]
                        }
                    ]
                },
                {
                    "node": "Minimal retrieval ability: synthetic key-value (KV) retrieval test",
                    "type": "depth-1 node",
                    "description": "Strip away natural-language semantics using random UUIDs in JSON key-value pairs to test whether models can retrieve the value for a given key when contexts are long and the target appears in different positions.",
                    "evidence": "Task motivation and setup in Sec.3 with example in Fig.6 (p.6).",
                    "children": [
                        {
                            "type": "leaf node",
                            "task": "Effect of target position and k on KV retrieval",
                            "dataset": ["Synthetic UUID JSONs (500 examples per k)"],
                            "model_or_method": ["GPT-3.5-Turbo / 16k", "Claude-1.3 / 100k", "MPT-30B-Instruct", "LongChat-13B-16k"],
                            "metrics": ["Accuracy (exact match of value)"],
                            "protocol_or_setup": "Key appears at specified ordinal positions; k‚àà{75 (~4K tokens), 140 (~8K), 300 (~16K)}; greedy decoding.",
                            "evidence": { "figure": "Fig.7 (p.7)", "section": "Sec.3.2 (pp.6‚Äì7)" },
                            "conclusion": "Claude variants are near-perfect across lengths. Other models again show a U-shape with worst accuracy when the key is in the middle."
                        }
                    ]
                },
                {
                    "node": "Why the position sensitivity? Factor analyses",
                    "type": "depth-1 node",
                    "description": "Probe how architecture, query placement, and instruction fine-tuning affect position robustness.",
                    "evidence": "Section 4 overview and sub-sections.",
                    "children": [
                        {
                            "node": "Role of architecture: encoder-decoder vs decoder-only",
                            "type": "depth-2 node",
                            "description": "Compare Flan-UL2 / Flan-T5-XXL (encoder-decoder) to decoder-only models under the same MD-QA protocol.",
                            "evidence": "Sec.4.1 with plots in Fig.8 (p.8).",
                            "children": [
                                {
                                    "type": "leaf node",
                                    "task": "Encoder-decoder models within vs beyond their training-time context length",
                                    "dataset": ["NaturalQuestions-Open subset for MD-QA"],
                                    "model_or_method": ["Flan-UL2", "Flan-T5-XXL", "Decoder-only baselines"],
                                    "metrics": ["Accuracy by answer-passage position"],
                                    "protocol_or_setup": "Evaluate at ~2K, ~4K, ~6K token contexts (10/20/30 docs) to test within and beyond training windows.",
                                    "evidence": { "figure": "Fig.8 (p.8)", "section": "Sec.4.1 (pp.7‚Äì8)" },
                                    "conclusion": "Encoder-decoder models are relatively robust to position when sequences fit within their encoder's training-time length."
                                }
                            ]
                        }
                    ]
                }
            ]
        }
    },
    {
        paper: {
            title: "Large Language Models Cannot Self-Correct Reasoning Yet",
            authors: ["Jie Huang", "Xinyun Chen", "Swaroop Mishra", "Huaixiu Steven Zheng", "Adams Wei Yu", "Xinying Song", "Denny Zhou"],
            venue: "ICLR",
            year: "2024"
        },
        problem_tree: {
            "node": "Can large language models (LLMs) intrinsically self-correct their own reasoning‚Äîwithout any external feedback‚Äîand if not, why, and what evaluation pitfalls obscure this?",
            "type": "root node",
            "description": "The paper defines \"intrinsic self-correction\" (LLMs revise answers using only internal signals) and empirically examines whether it improves reasoning. It contrasts this with oracle-labeled self-correction, analyzes behavioral dynamics of revisions, compares to alternative multi-response methods at matched inference cost, and inspects prompt-design confounds.",
            "evidence": "Abstract & ¬ß1‚Äì2 define scope and the intrinsic setting; main claim that performance often deteriorates after self-correction; overview of later sections (¬ß3‚Äì5).",
            "children": [
                {
                    "node": "Establish and evaluate intrinsic self-correction for reasoning tasks",
                    "type": "depth-1 node",
                    "description": "Lay out datasets, models, prompting protocol; first show oracle-gated self-correction as an upper bound; then remove labels so models must decide when/how to revise; probe different feedback prompts; analyze answer-change patterns.",
                    "evidence": "¬ß3.1 describes datasets (GSM8K, CommonSenseQA, HotpotQA), models (GPT-3.5/4/4-Turbo, Llama-2), and three-step prompting with up to two correction rounds; ¬ß3.2‚Äì3.3 report results and analyses.",
                    "children": [
                        {
                            "node": "Oracle-gated self-correction as an upper-bound reference",
                            "type": "depth-2 node",
                            "description": "Use ground-truth labels to halt the correction loop whenever the model's answer is correct.",
                            "evidence": "¬ß3.2; Table 2 (p.4) shows gains with labels for GPT-3.5 and GPT-4.",
                            "children": [
                                {
                                    "type": "leaf node",
                                    "task": "Self-correct with oracle labels on reasoning benchmarks",
                                    "dataset": ["GSM8K (test set, 1,319 problems)", "CommonSenseQA (dev set, 1,221 questions)", "HotpotQA (100-question subset)"],
                                    "model_or_method": ["GPT-3.5-Turbo", "GPT-4", "Three-step: initial ‚Üí feedback ‚Üí revised answer; oracle stops loop"],
                                    "metrics": ["Accuracy (GSM8K, CommonSenseQA)", "Exact Match (HotpotQA)"],
                                    "protocol_or_setup": "Oracle label used each step to verify correctness and stop; otherwise proceed.",
                                    "evidence": { "table": "Table 2 (p.4)", "section": "Sec. 3.2" },
                                    "conclusion": "With oracle labels, performance increases markedly (e.g., GPT-3.5: GSM8K 75.9‚Üí84.3), indicating that improvements hinge on external correctness signals."
                                }
                            ]
                        },
                        {
                            "node": "Intrinsic self-correction without labels across models/datasets",
                            "type": "depth-2 node",
                            "description": "Remove access to labels; the LLM must judge whether to revise/retain answers using only its own feedback.",
                            "evidence": "¬ß3.2; Tables 3‚Äì4 (pp.4‚Äì5) report accuracies and #calls.",
                            "children": [
                                {
                                    "type": "leaf node",
                                    "task": "Intrinsic self-correction on GPT-3.5 and GPT-4",
                                    "dataset": ["GSM8K", "CommonSenseQA", "HotpotQA"],
                                    "model_or_method": ["GPT-3.5-Turbo (full eval sets)", "GPT-4 (200-sample per dataset)", "Three-step intrinsic self-correction (no labels)"],
                                    "metrics": ["Accuracy (GSM8K, CommonSenseQA)", "Exact Match (HotpotQA)"],
                                    "protocol_or_setup": "Max two correction rounds (3 and 5 model calls); temperature 1; models decide to keep/change answers.",
                                    "evidence": { "table": "Table 3 (p.4)", "section": "Sec. 3.2; setup in Sec. 3.1" },
                                    "conclusion": "Accuracy drops after self-correction: GPT-3.5 (GSM8K 75.9‚Üí75.1‚Üí74.7) and GPT-4 (GSM8K 95.5‚Üí91.5‚Üí89.0)."
                                }
                            ]
                        },
                        {
                            "node": "Behavioral analysis: how answers change under intrinsic self-correction",
                            "type": "depth-2 node",
                            "description": "Quantify whether revisions tend to fix wrong answers or corrupt correct ones; provide qualitative cases.",
                            "evidence": "¬ß3.3; Figure 1 (p.6) summarizes change categories across models/datasets.",
                            "children": [
                                {
                                    "type": "leaf node",
                                    "task": "Quantify answer-change categories after two rounds",
                                    "dataset": ["GSM8K", "CommonSenseQA"],
                                    "model_or_method": ["GPT-3.5", "GPT-4", "GPT-4-Turbo", "Llama-2"],
                                    "metrics": ["Proportion per category: No Change; Correct‚ÜíIncorrect; Incorrect‚ÜíCorrect; Incorrect‚ÜíIncorrect"],
                                    "protocol_or_setup": "Compute distribution of change categories after two intrinsic self-correction rounds.",
                                    "evidence": { "figure": "Figure 1 (p.6)", "section": "Sec. 3.3" },
                                    "conclusion": "Models often retain initial answers; when they do change, they are more likely to flip a correct answer to an incorrect one."
                                }
                            ]
                        }
                    ]
                },
                {
                    "node": "Compare self-correction to alternatives at matched inference cost",
                    "type": "depth-1 node",
                    "description": "Since self-correction uses extra calls, compare debate-style multi-agent critique to self-consistency when controlling for the number of model generations.",
                    "evidence": "¬ß4 sets up a fair-cost comparison; Table 7 (p.7) juxtaposes multi-agent debate with self-consistency on GSM8K.",
                    "children": [
                        {
                            "type": "leaf node",
                            "task": "GSM8K: Multi-Agent Debate vs Self-Consistency",
                            "dataset": ["GSM8K (full test set)"],
                            "model_or_method": ["gpt-3.5-turbo-0301", "Multi-Agent Debate (3 agents; 2 rounds)", "Self-Consistency (majority vote with 3/6/9 samples)"],
                            "metrics": ["Accuracy"],
                            "protocol_or_setup": "Use the exact debate prompt from Du et al. (2023); match self-consistency to the same #responses.",
                            "evidence": { "table": "Table 7 (p.7)", "section": "Sec. 4" },
                            "conclusion": "Both exceed standard prompting, but debate does not beat self-consistency at the same cost."
                        }
                    ]
                }
            ]
        }
    },
    {
        paper: {
            title: "Unmasking and Quantifying Racial Bias of Large Language Models in Medical Report Generation",
            authors: ["Yifan Yang", "Xiaoyu Liu", "Qiao Jin", "Furong Huang", "Zhiyong Lu"],
            venue: "Communications Medicine",
            year: "2024"
        },
        problem_tree: {
            "node": "Root: Do state-of-the-art LLMs (GPT-3.5-turbo, GPT-4) exhibit racial/ethnic bias when generating medical case reports, and how can such bias be quantified and qualitatively characterized?",
            "type": "root node",
            "description": "The paper investigates whether LLMs inherit and express racial/ethnic biases in medical report generation and proposes methods to reveal, quantify, and analyze such biases across diagnosis, treatment, cost, hospitalization, and prognosis.",
            "evidence": "Title and abstract define the aim to unmask and quantify racial bias in LLM-generated medical reports; Introduction motivates the need in clinical contexts. (pp. 1‚Äì2, Abstract/Background).",
            "children": [
                {
                    "node": "Design a controlled bias-probing framework that holds clinical content constant and varies only racial/ethnic identifiers.",
                    "type": "depth-1 node",
                    "description": "Establish a pipeline to create hypothetical patient profiles from real cases, remove original race/ethnicity, inject target racial labels, and prompt LLMs to generate standardized multi-section reports for analysis.",
                    "evidence": "Methods‚ÄîDataset and Method overview; Fig. 1 workflow shows steps a‚Äìe. (pp. 2‚Äì3; Fig. 1 on p. 2).",
                    "children": [
                        {
                            "type": "leaf node",
                            "task": "Construct hypothetical patient profiles from PMC-Patients with race removed and re-injected",
                            "dataset": ["PMC-Patients (167,000 patient summaries); 200 recent cases for main reports; 200 deceased cases for survival analysis"],
                            "model_or_method": ["GPT-3.5-turbo-0301 and GPT-4-0613 (Azure) used for extraction and verification"],
                            "metrics": ["Not a quantitative metric; pipeline specification"],
                            "protocol_or_setup": "Remove race (Prompt B), inject target race (Prompt C); ensure recent articles to reduce memorization; manual MD review of condition commonality.",
                            "evidence": { "figure": "Fig. 1 (workflow, p. 2)", "section": "Methods‚ÄîDataset; Method overview" },
                            "conclusion": "A standardized, race-controlled set of hypothetical profiles was established for probing bias."
                        }
                    ]
                },
                {
                    "node": "Do LLMs exhibit racial bias in patient information processing and diagnosis generation?",
                    "type": "depth-1 node",
                    "description": "Assess whether paraphrasing of patient backgrounds and diagnoses differ by race when clinical presentation is held constant.",
                    "evidence": "Results‚Äî'Current LLMs present racial biases in medical diagnosis and patient information processing'. (p. 4).",
                    "children": [
                        {
                            "type": "leaf node",
                            "task": "Manual review of paraphrased patient descriptions and case history across races",
                            "dataset": ["200 main patient cases; 3 generations per combination for manual inspection"],
                            "model_or_method": ["GPT-3.5-turbo; qualitative annotators (n=3)"],
                            "metrics": ["Counts of biased/fabricated details (e.g., 16/200)"],
                            "protocol_or_setup": "Section-wise horizontal comparison across four racial labels for each patient; collect annotator comments.",
                            "evidence": { "section": "Results‚ÄîCurrent LLMs present racial biases‚Ä¶; Supplementary Table 2" },
                            "conclusion": "GPT-3.5-turbo added stereotyped or fabricated background details more often for certain racial groups."
                        },
                        {
                            "type": "leaf node",
                            "task": "Manual analysis of generated diagnosis sections across races",
                            "dataset": ["200 main patient cases; 3 generations per combination"],
                            "model_or_method": ["GPT-3.5-turbo; human qualitative coding"],
                            "metrics": ["Count and characterization of race-skewed diagnoses (21/200)"],
                            "protocol_or_setup": "Compare diagnosis sections across race-variants for each patient.",
                            "evidence": { "section": "Results‚ÄîCurrent LLMs present racial biases‚Ä¶; Supplementary Table 2" },
                            "conclusion": "LLM diagnostic outputs reflected stereotyped race‚Äìdisease associations and severity patterns."
                        }
                    ]
                },
                {
                    "node": "Quantify racial disparities in projected costs and hospitalization durations.",
                    "type": "depth-1 node",
                    "description": "Measure whether projected cost and length of stay differ pair-wise across racial groups and validate with statistical tests.",
                    "evidence": "Results‚Äîquantitative comparisons summarized in Fig. 2; Statistics and reproducibility (z-tests). (p. 4; Fig. 2 on p. 4).",
                    "children": [
                        {
                            "type": "leaf node",
                            "task": "Projected hospitalization duration comparisons (pair-wise win rates) with GPT-3.5-turbo",
                            "dataset": ["200 main cases √ó 4 races; 10 generations per combination"],
                            "model_or_method": ["GPT-3.5-turbo-0301; rule-based extraction"],
                            "metrics": ["Pair-wise win rate (e.g., White vs Black 58.5% vs 41.5%); two-sided z-tests; p-values"],
                            "protocol_or_setup": "High-temperature report generation; extract 'Expected hospitalized days' and compare across race pairs.",
                            "evidence": { "figure": "Fig. 2a (p. 4)", "section": "Statistics and reproducibility" },
                            "conclusion": "GPT-3.5-turbo more frequently predicts longer stays for white patients across pairs, with several comparisons statistically significant."
                        },
                        {
                            "type": "leaf node",
                            "task": "Projected cost comparisons (pair-wise win rates) with GPT-3.5-turbo",
                            "dataset": ["Same 200 main cases √ó 4 races; 10 gens per combo"],
                            "model_or_method": ["GPT-3.5-turbo-0301; numeric extraction"],
                            "metrics": ["Pair-wise win rate for higher cost; z-tests with p-values"],
                            "protocol_or_setup": "Extract 'Expected cost in dollars if no insurance'; compute pair-wise win rates and run two-sided z-tests.",
                            "evidence": { "figure": "Fig. 2b (p. 4)", "section": "Statistics and reproducibility" },
                            "conclusion": "Costs are projected higher more often for white patients than others; ranking by win rate: white > Black > Hispanic > Asian."
                        }
                    ]
                }
            ]
        }
    }
];

let currentTreePaper = 0;

function getTreeNodeClass(type) {
    const typeMap = {
        'root node': 'tree-root-node',
        'depth-1 node': 'tree-depth-1-node',
        'depth-2 node': 'tree-depth-2-node',
        'depth-3 node': 'tree-depth-3-node',
        'leaf node': 'tree-leaf-node'
    };
    return typeMap[type] || 'tree-depth-1-node';
}

function renderTreeEvidence(evidence) {
    if (typeof evidence === 'string') {
        return `<div class="tree-node-evidence">üìñ ${evidence}</div>`;
    }
    if (typeof evidence === 'object') {
        let refs = [];
        if (evidence.figure) refs.push(`üìä ${evidence.figure}`);
        if (evidence.table) refs.push(`üìã ${evidence.table}`);
        if (evidence.section) refs.push(`üìñ ${evidence.section}`);
        if (refs.length === 0) return '';
        return `<div class="tree-evidence-refs">${refs.map(r => `<span class="tree-evidence-ref">${r}</span>`).join('')}</div>`;
    }
    return '';
}

function renderTreeLeafNode(node) {
    let html = `<div class="tree-leaf-details">`;
    
    html += `<div class="tree-detail-row"><span class="tree-detail-label">Task:</span><span class="tree-detail-value">${node.task}</span></div>`;
    
    if (node.dataset && node.dataset.length) {
        html += `<div class="tree-detail-row"><span class="tree-detail-label">Dataset:</span><span class="tree-detail-value">${node.dataset.map(d => `<span class="tree-tag">${d}</span>`).join(' ')}</span></div>`;
    }
    
    if (node.model_or_method && node.model_or_method.length) {
        html += `<div class="tree-detail-row"><span class="tree-detail-label">Models:</span><span class="tree-detail-value">${node.model_or_method.map(m => `<span class="tree-tag">${m}</span>`).join(' ')}</span></div>`;
    }
    
    if (node.metrics && node.metrics.length) {
        html += `<div class="tree-detail-row"><span class="tree-detail-label">Metrics:</span><span class="tree-detail-value">${node.metrics.join(', ')}</span></div>`;
    }
    
    if (node.protocol_or_setup) {
        html += `<div class="tree-detail-row"><span class="tree-detail-label">Setup:</span><span class="tree-detail-value">${node.protocol_or_setup}</span></div>`;
    }
    
    if (node.evidence) {
        html += renderTreeEvidence(node.evidence);
    }
    
    if (node.conclusion) {
        html += `<div class="tree-conclusion-box"><div class="tree-label">Conclusion</div><div class="tree-text">${node.conclusion}</div></div>`;
    }
    
    html += `</div>`;
    return html;
}

function countTreeNodes(node) {
    let counts = { total: 1, leaves: 0, depth1: 0, depth2: 0 };
    if (node.type === 'leaf node') counts.leaves = 1;
    if (node.type === 'depth-1 node') counts.depth1 = 1;
    if (node.type === 'depth-2 node') counts.depth2 = 1;
    
    if (node.children) {
        for (const child of node.children) {
            const childCounts = countTreeNodes(child);
            counts.total += childCounts.total;
            counts.leaves += childCounts.leaves;
            counts.depth1 += childCounts.depth1;
            counts.depth2 += childCounts.depth2;
        }
    }
    return counts;
}

function renderTreeNode(node, depth = 0) {
    const isLeaf = node.type === 'leaf node';
    const hasChildren = node.children && node.children.length > 0;
    const nodeClass = getTreeNodeClass(node.type);
    const title = node.node || node.task || 'Untitled';
    
    let html = `<div class="tree-node ${nodeClass}${depth > 0 ? ' collapsed' : ''}" data-depth="${depth}">`;
    html += `<div class="tree-node-header" onclick="toggleTreeNode(this.parentElement)">`;
    html += `<span class="tree-toggle-icon">${(hasChildren || isLeaf) ? '‚ñº' : ''}</span>`;
    html += `<span class="tree-node-type">${node.type}</span>`;
    html += `<span class="tree-node-title">${title}</span>`;
    html += `</div>`;
    
    html += `<div class="tree-node-content">`;
    
    if (isLeaf) {
        html += renderTreeLeafNode(node);
    } else {
        if (node.description) {
            html += `<div class="tree-node-description">${node.description}</div>`;
        }
        if (node.evidence) {
            html += renderTreeEvidence(node.evidence);
        }
    }
    
    if (hasChildren) {
        html += `<div class="tree-children">`;
        for (const child of node.children) {
            html += renderTreeNode(child, depth + 1);
        }
        html += `</div>`;
    }
    
    html += `</div>`;
    html += `</div>`;
    
    return html;
}

function renderTreePaper(index) {
    const data = treePapers[index];
    const counts = countTreeNodes(data.problem_tree);
    
    let html = `
        <div class="tree-header">
            <h3>${data.paper.title}</h3>
            <div class="tree-authors">${data.paper.authors.join(', ')}</div>
            <div class="tree-venue">${data.paper.venue}, ${data.paper.year}</div>
        </div>
        <div class="tree-stats-bar">
            <div class="tree-stat-item">
                <div class="tree-stat-value">${counts.total}</div>
                <div class="tree-stat-label">Total Nodes</div>
            </div>
            <div class="tree-stat-item">
                <div class="tree-stat-value">${counts.depth1}</div>
                <div class="tree-stat-label">Main Branches</div>
            </div>
            <div class="tree-stat-item">
                <div class="tree-stat-value">${counts.leaves}</div>
                <div class="tree-stat-label">Experiments</div>
            </div>
        </div>
        <div class="tree-container">
            ${renderTreeNode(data.problem_tree)}
        </div>
    `;
    
    return html;
}

let currentTreeView = 'interactive';

function switchTreePaper(index) {
    currentTreePaper = index;
    
    // Update tabs
    document.querySelectorAll('.tree-paper-tab').forEach((tab, i) => {
        tab.classList.toggle('active', i === index);
    });
    
    // Update interactive tree content
    document.querySelectorAll('.tree-paper-content').forEach((content, i) => {
        content.classList.toggle('active', i === index);
    });
    
    // Update diagram content
    document.querySelectorAll('.tree-diagram-content').forEach((content, i) => {
        content.classList.toggle('active', i === index);
    });
}

function switchTreeView(view) {
    currentTreeView = view;
    
    // Update view toggle buttons
    document.querySelectorAll('.tree-view-btn').forEach(btn => {
        btn.classList.remove('active');
    });
    event.currentTarget.classList.add('active');
    
    // Show/hide the appropriate view container
    const interactiveView = document.getElementById('tree-interactive-view');
    const diagramView = document.getElementById('tree-diagram-view');
    const sidebar = document.getElementById('tree-sidebar');
    
    if (view === 'interactive') {
        interactiveView.classList.add('active');
        diagramView.classList.remove('active');
        sidebar.style.display = 'block';
    } else {
        interactiveView.classList.remove('active');
        diagramView.classList.add('active');
        sidebar.style.display = 'none';
    }
}

function toggleTreeNode(nodeEl) {
    nodeEl.classList.toggle('collapsed');
}

function expandAllTree() {
    const activeContent = document.querySelector('.tree-paper-content.active');
    activeContent.querySelectorAll('.tree-node').forEach(n => n.classList.remove('collapsed'));
}

function collapseAllTree() {
    const activeContent = document.querySelector('.tree-paper-content.active');
    activeContent.querySelectorAll('.tree-node').forEach(n => {
        if (n.dataset.depth > 0) n.classList.add('collapsed');
    });
}

function expandTreeToDepth(maxDepth) {
    const activeContent = document.querySelector('.tree-paper-content.active');
    activeContent.querySelectorAll('.tree-node').forEach(n => {
        const depth = parseInt(n.dataset.depth);
        if (depth <= maxDepth) {
            n.classList.remove('collapsed');
        } else {
            n.classList.add('collapsed');
        }
    });
}

// Initialize all tree papers on page load
document.addEventListener('DOMContentLoaded', function() {
    treePapers.forEach((_, index) => {
        const container = document.getElementById(`tree-paper-${index}`);
        if (container) {
            container.innerHTML = renderTreePaper(index);
        }
    });
});
</script>

</body>
</html>
